{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5497ac",
   "metadata": {},
   "source": [
    "***Purpose of this Notebook***\n",
    "\n",
    "This notebook evaluates the performance of the rule-based regular expression (regex) extraction baseline against a human-labeled gold dataset. Evaluation metrics include precision, recall, and F1 score, calculated using the same gold annotations that define ground truth. No extraction logic is modified or introduced in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d45936a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c244c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd().parent\n",
    "GOLD_DIR = PROJECT_ROOT / \"gold_annotations\"\n",
    "\n",
    "EVAL_FILES = [\n",
    "    '1017655_10K_2020_0001654954-21-003649.json.gold.json',\n",
    "    '1064722_10K_2020_0001760319-21-000039.json.gold.json',\n",
    "    '1066684_10K_2020_0001104659-21-042359.json.gold.json',\n",
    "    '1082324_10K_2020_0001140361-21-008678.json.gold.json',\n",
    "    '1327567_10K_2021_0001327567-21-000029.json.gold.json',\n",
    "    '1353499_10K_2020_0001344676-21-000004.json.gold.json',\n",
    "    '1378590_10K_2021_0001437749-21-028984.json.gold.json',\n",
    "    '1404655_10K_2020_0001564590-21-006083.json.gold.json'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b4a4a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "      <th>section</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1017655_10K_2020_0001654954-21-003649</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>item_7</td>\n",
       "      <td>$3,541</td>\n",
       "      <td>13031</td>\n",
       "      <td>13037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1017655_10K_2020_0001654954-21-003649</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>item_7</td>\n",
       "      <td>$19,395</td>\n",
       "      <td>13038</td>\n",
       "      <td>13045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1017655_10K_2020_0001654954-21-003649</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>item_7</td>\n",
       "      <td>27,845</td>\n",
       "      <td>13081</td>\n",
       "      <td>13087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1017655_10K_2020_0001654954-21-003649</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>item_7</td>\n",
       "      <td>148,035</td>\n",
       "      <td>13088</td>\n",
       "      <td>13095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017655_10K_2020_0001654954-21-003649</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>item_7</td>\n",
       "      <td>114,881</td>\n",
       "      <td>13130</td>\n",
       "      <td>13137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file  label section     text  start    end\n",
       "0  1017655_10K_2020_0001654954-21-003649  MONEY  item_7   $3,541  13031  13037\n",
       "1  1017655_10K_2020_0001654954-21-003649  MONEY  item_7  $19,395  13038  13045\n",
       "2  1017655_10K_2020_0001654954-21-003649  MONEY  item_7   27,845  13081  13087\n",
       "3  1017655_10K_2020_0001654954-21-003649  MONEY  item_7  148,035  13088  13095\n",
       "4  1017655_10K_2020_0001654954-21-003649  MONEY  item_7  114,881  13130  13137"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def load_gold_annotations(gold_dir: Path, eval_files: list[str]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for fname in eval_files:\n",
    "        fp = gold_dir / fname\n",
    "        data = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "        anns = data.get(\"annotations\", data)  # supports either {annotations:[...]} or just [...]\n",
    "\n",
    "        # normalize file id to match the source file stem\n",
    "        # e.g. \"...042359.json.gold.json\" -> \"...042359\"\n",
    "        file_id = Path(fname.replace(\".gold.json\", \"\")).stem\n",
    "\n",
    "        for a in anns:\n",
    "            rows.append({\n",
    "                \"file\": file_id,\n",
    "                \"label\": a[\"label\"],\n",
    "                \"section\": a[\"section\"],\n",
    "                \"text\": a[\"text\"],\n",
    "                \"start\": a.get(\"start\"),\n",
    "                \"end\": a.get(\"end\"),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "gold_df = load_gold_annotations(GOLD_DIR, EVAL_FILES)\n",
    "gold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4745c0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "      <th>section</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1017655_10K_2020_0001654954-21-003649</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>item_10</td>\n",
       "      <td>Austin Lewis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1017655_10K_2020_0001654954-21-003649</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>item_10</td>\n",
       "      <td>David Scott</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1017655_10K_2020_0001654954-21-003649</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>item_10</td>\n",
       "      <td>Andrew Pilaro</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1017655_10K_2020_0001654954-21-003649</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>item_10</td>\n",
       "      <td>Allan Pratt</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017655_10K_2020_0001654954-21-003649</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>item_10</td>\n",
       "      <td>Under Delaware</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file   label  section            text  \\\n",
       "0  1017655_10K_2020_0001654954-21-003649  PERSON  item_10    Austin Lewis   \n",
       "1  1017655_10K_2020_0001654954-21-003649  PERSON  item_10     David Scott   \n",
       "2  1017655_10K_2020_0001654954-21-003649  PERSON  item_10   Andrew Pilaro   \n",
       "3  1017655_10K_2020_0001654954-21-003649  PERSON  item_10     Allan Pratt   \n",
       "4  1017655_10K_2020_0001654954-21-003649  PERSON  item_10  Under Delaware   \n",
       "\n",
       "  start   end  \n",
       "0  None  None  \n",
       "1  None  None  \n",
       "2  None  None  \n",
       "3  None  None  \n",
       "4  None  None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ROOT = Path.cwd().parent\n",
    "BASELINE_PATH = PROJECT_ROOT / \"baseline_regex_outputs.json\"\n",
    "\n",
    "LABELS = [\"PERSON\", \"TITLE\", \"ORG\", \"MONEY\"]\n",
    "\n",
    "def load_baseline_predictions(baseline_path: Path, eval_file_ids: set[str]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    data = json.loads(baseline_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    def section_for_label(label: str) -> str:\n",
    "        return \"item_7\" if label == \"MONEY\" else \"item_10\"\n",
    "\n",
    "    # Case A: { \"<filename>.json\": { \"PERSON\":[...], ... }, ... }\n",
    "    if isinstance(data, dict):\n",
    "        for file_key, payload in data.items():\n",
    "            file_id = Path(file_key).stem  # \"....json\" -> \"....\"\n",
    "            if file_id not in eval_file_ids:\n",
    "                continue\n",
    "\n",
    "            for label in LABELS:\n",
    "                values = payload.get(label, []) or []\n",
    "                for v in values:\n",
    "                    rows.append({\n",
    "                        \"file\": file_id,\n",
    "                        \"label\": label,\n",
    "                        \"section\": section_for_label(label),\n",
    "                        \"text\": str(v),\n",
    "                        \"start\": None,\n",
    "                        \"end\": None,\n",
    "                    })\n",
    "\n",
    "    # Case B: [ { \"file\":\"<filename>.json\", \"PERSON\":[...], ... }, ... ]\n",
    "    elif isinstance(data, list):\n",
    "        for obj in data:\n",
    "            file_key = obj.get(\"file\") or obj.get(\"filename\") or obj.get(\"FILE\")\n",
    "            if not file_key:\n",
    "                continue\n",
    "\n",
    "            file_id = Path(file_key).stem\n",
    "            if file_id not in eval_file_ids:\n",
    "                continue\n",
    "\n",
    "            for label in LABELS:\n",
    "                values = obj.get(label, []) or []\n",
    "                for v in values:\n",
    "                    rows.append({\n",
    "                        \"file\": file_id,\n",
    "                        \"label\": label,\n",
    "                        \"section\": section_for_label(label),\n",
    "                        \"text\": str(v),\n",
    "                        \"start\": None,\n",
    "                        \"end\": None,\n",
    "                    })\n",
    "    else:\n",
    "        raise ValueError(\"baseline_regex_outputs.json is neither a dict nor a list\")\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Use the gold_df you already built to define the evaluation file universe\n",
    "eval_file_ids = set(gold_df[\"file\"].unique())\n",
    "\n",
    "baseline_df = load_baseline_predictions(BASELINE_PATH, eval_file_ids)\n",
    "baseline_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c713ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_text(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Lightweight normalization to reduce false mismatches due to casing/whitespace.\n",
    "    Keeps meaning intact (no punctuation stripping, no stemming, etc.).\n",
    "    \"\"\"\n",
    "    s = \"\" if s is None else str(s)\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)  # collapse internal whitespace\n",
    "    return s\n",
    "\n",
    "\n",
    "def to_counts(df: pd.DataFrame, count_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Turn row-level entities into a multiset count table by (file,label,section,text_n).\n",
    "    Using text_n (normalized text) improves fairness for string-based baseline evaluation.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"text_n\"] = df[\"text\"].map(norm_text)\n",
    "\n",
    "    return (\n",
    "        df.groupby([\"file\", \"label\", \"section\", \"text_n\"])\n",
    "          .size()\n",
    "          .reset_index(name=count_col)\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_metrics(gold_df: pd.DataFrame, baseline_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Compute TP/FP/FN using multiset exact matching on normalized text.\n",
    "    Returns:\n",
    "      - merged: row-level match table (one row per unique (file,label,section,text_n))\n",
    "      - by_label: micro totals + PRF per label\n",
    "      - overall: micro totals + PRF overall\n",
    "    \"\"\"\n",
    "    gold_counts = to_counts(gold_df, \"gold_n\")\n",
    "    base_counts = to_counts(baseline_df, \"pred_n\")\n",
    "\n",
    "    merged = gold_counts.merge(\n",
    "        base_counts,\n",
    "        on=[\"file\", \"label\", \"section\", \"text_n\"],\n",
    "        how=\"outer\"\n",
    "    ).fillna(0)\n",
    "\n",
    "    merged[\"tp\"] = merged[[\"gold_n\", \"pred_n\"]].min(axis=1)\n",
    "    merged[\"fp\"] = merged[\"pred_n\"] - merged[\"tp\"]\n",
    "    merged[\"fn\"] = merged[\"gold_n\"] - merged[\"tp\"]\n",
    "\n",
    "    def prf(tp, fp, fn):\n",
    "        precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "        recall    = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "        f1        = (2 * precision * recall / (precision + recall)) if (precision + recall) else 0.0\n",
    "        return precision, recall, f1\n",
    "\n",
    "    # Per-label totals (micro by label)\n",
    "    by_label = (\n",
    "        merged.groupby(\"label\")[[\"tp\", \"fp\", \"fn\"]]\n",
    "              .sum()\n",
    "              .reset_index()\n",
    "    )\n",
    "\n",
    "    by_label[[\"precision\", \"recall\", \"f1\"]] = by_label.apply(\n",
    "        lambda r: pd.Series(prf(r.tp, r.fp, r.fn)),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Overall micro-average\n",
    "    tp_all, fp_all, fn_all = merged[[\"tp\", \"fp\", \"fn\"]].sum()\n",
    "    p_all, r_all, f1_all = prf(tp_all, fp_all, fn_all)\n",
    "\n",
    "    overall = {\n",
    "        \"tp\": int(tp_all),\n",
    "        \"fp\": int(fp_all),\n",
    "        \"fn\": int(fn_all),\n",
    "        \"precision\": float(p_all),\n",
    "        \"recall\": float(r_all),\n",
    "        \"f1\": float(f1_all),\n",
    "    }\n",
    "\n",
    "    return merged, by_label, overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06e18578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERALL REGEX BASELINE (micro):\n",
      "{'tp': 126, 'fp': 126, 'fn': 1095, 'precision': 0.5, 'recall': 0.103, 'f1': 0.171}\n",
      "\n",
      "PER-LABEL PERFORMANCE (micro):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MONEY</td>\n",
       "      <td>71.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORG</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PERSON</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TITLE</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label    tp    fp     fn  precision  recall     f1\n",
       "0   MONEY  71.0  92.0  871.0      0.436   0.075  0.129\n",
       "1     ORG   8.0   7.0   77.0      0.533   0.094  0.160\n",
       "2  PERSON  15.0  24.0   38.0      0.385   0.283  0.326\n",
       "3   TITLE  32.0   3.0  109.0      0.914   0.227  0.364"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exported Sprint 3 regex scores to:\n",
      "C:\\Users\\abrid\\OneDrive\\Desktop\\WGU Work\\D502 (CAPSTONE)\\Task 3\\Notebooks\\exports\\regex_scores_per_doc.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>variant</th>\n",
       "      <th>section</th>\n",
       "      <th>mode</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1017655_10K_2020_0001654954-21-003649.json</td>\n",
       "      <td>regex_baseline</td>\n",
       "      <td>item_10</td>\n",
       "      <td>strict</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.209677</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1017655_10K_2020_0001654954-21-003649.json</td>\n",
       "      <td>regex_baseline</td>\n",
       "      <td>item_7</td>\n",
       "      <td>strict</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.147059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1064722_10K_2020_0001760319-21-000039.json</td>\n",
       "      <td>regex_baseline</td>\n",
       "      <td>item_10</td>\n",
       "      <td>strict</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1064722_10K_2020_0001760319-21-000039.json</td>\n",
       "      <td>regex_baseline</td>\n",
       "      <td>item_7</td>\n",
       "      <td>strict</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1066684_10K_2020_0001104659-21-042359.json</td>\n",
       "      <td>regex_baseline</td>\n",
       "      <td>item_10</td>\n",
       "      <td>strict</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filename         variant  section  \\\n",
       "0  1017655_10K_2020_0001654954-21-003649.json  regex_baseline  item_10   \n",
       "1  1017655_10K_2020_0001654954-21-003649.json  regex_baseline   item_7   \n",
       "2  1064722_10K_2020_0001760319-21-000039.json  regex_baseline  item_10   \n",
       "3  1064722_10K_2020_0001760319-21-000039.json  regex_baseline   item_7   \n",
       "4  1066684_10K_2020_0001104659-21-042359.json  regex_baseline  item_10   \n",
       "\n",
       "     mode    tp   fp    fn  precision    recall        f1  \n",
       "0  strict  13.0  3.0  49.0   0.812500  0.209677  0.333333  \n",
       "1  strict   5.0  0.0  58.0   1.000000  0.079365  0.147059  \n",
       "2  strict   9.0  6.0  48.0   0.600000  0.157895  0.250000  \n",
       "3  strict   5.0  0.0  10.0   1.000000  0.333333  0.500000  \n",
       "4  strict   7.0  4.0  11.0   0.636364  0.388889  0.482759  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Run evaluation ---\n",
    "merged_df, by_label_df, overall = compute_metrics(gold_df, baseline_df)\n",
    "\n",
    "print(\"OVERALL REGEX BASELINE (micro):\")\n",
    "print({\n",
    "    \"tp\": overall[\"tp\"],\n",
    "    \"fp\": overall[\"fp\"],\n",
    "    \"fn\": overall[\"fn\"],\n",
    "    \"precision\": round(overall[\"precision\"], 3),\n",
    "    \"recall\": round(overall[\"recall\"], 3),\n",
    "    \"f1\": round(overall[\"f1\"], 3),\n",
    "})\n",
    "\n",
    "print(\"\\nPER-LABEL PERFORMANCE (micro):\")\n",
    "display(\n",
    "    by_label_df\n",
    "    .sort_values(\"label\")\n",
    "    .assign(\n",
    "        precision=lambda d: d[\"precision\"].round(3),\n",
    "        recall=lambda d: d[\"recall\"].round(3),\n",
    "        f1=lambda d: d[\"f1\"].round(3),\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- Build per-document, per-section scores for Sprint 3 ---\n",
    "def prf(tp, fp, fn):\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    f1        = (2 * precision * recall / (precision + recall)) if (precision + recall) else 0.0\n",
    "    return precision, recall, f1\n",
    "\n",
    "per_doc = (\n",
    "    merged_df.groupby([\"file\", \"section\"])[[\"tp\", \"fp\", \"fn\"]]\n",
    "             .sum()\n",
    "             .reset_index()\n",
    ")\n",
    "\n",
    "per_doc[\"filename\"] = per_doc[\"file\"].astype(str) + \".json\"\n",
    "per_doc[\"variant\"] = \"regex_baseline\"\n",
    "per_doc[\"mode\"] = \"strict\"\n",
    "\n",
    "per_doc[[\"precision\", \"recall\", \"f1\"]] = per_doc.apply(\n",
    "    lambda r: pd.Series(prf(r.tp, r.fp, r.fn)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "per_doc = per_doc[[\n",
    "    \"filename\", \"variant\", \"section\", \"mode\",\n",
    "    \"tp\", \"fp\", \"fn\", \"precision\", \"recall\", \"f1\"\n",
    "]]\n",
    "\n",
    "# --- Add overall row (useful for headline tables) ---\n",
    "overall_row = pd.DataFrame([{\n",
    "    \"filename\": \"ALL_DOCS\",\n",
    "    \"variant\": \"regex_baseline\",\n",
    "    \"section\": \"overall\",\n",
    "    \"mode\": \"strict\",\n",
    "    \"tp\": overall[\"tp\"],\n",
    "    \"fp\": overall[\"fp\"],\n",
    "    \"fn\": overall[\"fn\"],\n",
    "    \"precision\": overall[\"precision\"],\n",
    "    \"recall\": overall[\"recall\"],\n",
    "    \"f1\": overall[\"f1\"],\n",
    "}])\n",
    "\n",
    "regex_scores = pd.concat([per_doc, overall_row], ignore_index=True)\n",
    "\n",
    "# --- Export for Sprint 3 ---\n",
    "out_path = Path(\"exports\") / \"regex_scores_per_doc.csv\"\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "regex_scores.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"\\nExported Sprint 3 regex scores to:\")\n",
    "print(out_path.resolve())\n",
    "\n",
    "display(regex_scores.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4293c407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cdd8bf2",
   "metadata": {},
   "source": [
    "A True Positive (TP) occurs when:\n",
    "\n",
    "gold label == regex label\n",
    "\n",
    "gold text is exactly present in the regex list for that label\n",
    "\n",
    "A False Negative (FN) occurs when:\n",
    "\n",
    "gold text is not present in the regex list for that label\n",
    "\n",
    "A False Positive (FP) occurs when:\n",
    "\n",
    "regex extracted a string under a label\n",
    "\n",
    "that string does not appear anywhere in gold for that label in that file\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall    = TP / (TP + FN)\n",
    "f1        = harmonic mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b9728a",
   "metadata": {},
   "source": [
    "The regex baseline produced high precision for TITLE entities (0.91), indicating that when the rules identified a title, it was usually correct. However, recall for TITLE remained low (0.23), suggesting the rule set was conservative and missed many valid titles. PERSON and ORG extraction showed both low precision and low recall, reflecting the difficulty of reliably identifying names and organizations in SEC filings using pattern-based rules alone (e.g., false positives from capitalized phrases and structural/legal boilerplate). MONEY recall was especially low (0.08) because the gold standard includes many numeric monetary-like values beyond dollar-prefixed currency strings; the regex baseline primarily captured explicit currency formats, leading to systematic under-identification relative to the broader gold definition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
