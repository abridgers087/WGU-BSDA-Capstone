{"cells":[{"cell_type":"markdown","id":"37bda864","metadata":{"id":"37bda864"},"source":["Model choice (en_core_web_sm vs others)\n","\n","stronger baseline NER out of the box: en_core_web_trf (transformer).\n","\n","Keep sm for iteration/debug (fast feedback). Add a second track where you run the exact same probe suites through en_core_web_trf during testing to quantify how much you gain from a stronger baseline."]},{"cell_type":"markdown","id":"4ee6c9cb","metadata":{"id":"4ee6c9cb"},"source":["1. Notebook Configuration\n","2. Global Constants and Constraints\n","3. Model Loading & Pipeline Assembly\n","4. Entity Modules\n","- 4.1 `PERSON`\n","- 4.2 `TITLE`\n","- 4.3 `MONEY`\n","- 4.4 `ORG`\n","5. Shared Helpers (Printing, Selection, Normalization)\n","6. Data loading + canonical doc objects\n","7. Gold parsing + alignment validator\n","- 7.1 Section Scope\n","- 7.2 Gold Assumptions\n","- 7.3 Prediction Source\n","- 7.4 Alignment Modes\n","- 7.5 Match Accounting\n","- 7.6 Metrics\n","8. Run harness (Single + Twin)\n","- 8.1 Execution Mode\n","- 8.2 Section Routing\n","- 8.3 Pipeline Variants\n","- 8.4 Prediction Normalization\n","- 8.5 Harness Outputs\n","9. Outputs (human + machine)\n","- 9.1 Machine Outputs\n","- 9.2 Human Outputs\n","10. Scoring\n","11. Findings/Notes"]},{"cell_type":"markdown","id":"f593268e","metadata":{"id":"f593268e"},"source":["### 1. Notebook Configuration\n","- spacy: pipeline loading, docs\n","- EntityRuler: TITLE, MONEY_CANDIDATE, ORG_CANDIDATE rules\n","- Span: manual span construction (suffix merges, candidate spans)\n","- defaultdict: entity inventories grouped by label\n","- typing: keeps extractor contracts explicit and readable\n","- re: regex-backed patterns\n","- string: controlled punctuation handling (money/org normalization)\n"]},{"cell_type":"code","source":["# ===== Section 0.1: Environment Setup (Colab-safe) =====\n","\n","# Core spaCy\n","#!pip install -U spacy\n","\n","# Small English model\n","#!python -m spacy download en_core_web_sm\n","\n","# Transformer English model (large, slow, but higher quality)\n","!python -m spacy download en_core_web_trf\n"],"metadata":{"id":"TseYsGRQ-NWF","executionInfo":{"status":"ok","timestamp":1767372401746,"user_tz":360,"elapsed":35280,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e1fd53dc-568d-4886-c265-9efb61ed352a"},"id":"TseYsGRQ-NWF","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en-core-web-trf==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m866.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy-curated-transformers<1.0.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from en-core-web-trf==3.8.0) (0.3.1)\n","Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.1.1)\n","Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.0.9)\n","Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.9.0+cpu)\n","Requirement already satisfied: regex>=2022 in /usr/local/lib/python3.12/dist-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.11.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.0.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_trf')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["import spacy\n","\n","#Verify Models are loaded\n","for model in (\"en_core_web_sm\", \"en_core_web_trf\"):\n","    try:\n","        nlp = spacy.load(model)\n","        print(f\"{model} loaded | pipes={nlp.pipe_names}\")\n","    except Exception as e:\n","        print(f\"{model} FAILED:\", e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R-vo01ot-sv0","executionInfo":{"status":"ok","timestamp":1767372417738,"user_tz":360,"elapsed":15990,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"506fb1a2-fc56-44c3-b650-7ece9e25ac00"},"id":"R-vo01ot-sv0","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["en_core_web_sm loaded | pipes=['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n","en_core_web_trf loaded | pipes=['transformer', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"]}]},{"cell_type":"code","execution_count":3,"id":"84be6695","metadata":{"id":"84be6695","executionInfo":{"status":"ok","timestamp":1767372418423,"user_tz":360,"elapsed":684,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"outputs":[],"source":["\n","# Core NLP\n","from spacy.pipeline import EntityRuler\n","from spacy.tokens import Span as SpacySpan\n","\n","# Data structures / utilities\n","from collections import defaultdict, Counter\n","from typing import Any, List, Dict, Tuple, Iterable, Optional\n","from dataclasses import dataclass\n","from pathlib import Path\n","import json\n","from __future__ import annotations\n","import pandas as pd\n","\n","# Text / normalization helpers\n","import re\n","import string"]},{"cell_type":"code","source":["# Mount Drive and point to project\n","from google.colab import drive\n","\n","drive.mount(\"/content/drive\")\n","\n","PROJECT_ROOT = Path(\"/content/drive/MyDrive/Task 3\")\n","\n","DATA_PATH = PROJECT_ROOT / \"primary_data.json\"\n","GOLD_DIR = PROJECT_ROOT / \"gold_annotations\"\n","\n","assert DATA_PATH.exists(), DATA_PATH\n","assert GOLD_DIR.exists(), GOLD_DIR"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95OMoBFpYc7q","executionInfo":{"status":"ok","timestamp":1767372419251,"user_tz":360,"elapsed":815,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"bbe25014-ef96-450a-dd61-3db83c8f5c41"},"id":"95OMoBFpYc7q","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","id":"6f703584","metadata":{"id":"6f703584"},"source":["### 2. Global Entity Constraints (spaCy-Focused)\n","\n","This section defines shared constants used by spaCy-based extraction:\n","- EntityRuler patterns\n","- candidate filtering\n","- normalization and exclusion rules\n","\n","Regex-heavy extractors and legacy heuristics are intentionally excluded.\n","Those live in separate regex-focused notebooks."]},{"cell_type":"code","execution_count":5,"id":"085b181d","metadata":{"id":"085b181d","executionInfo":{"status":"ok","timestamp":1767372419254,"user_tz":360,"elapsed":1,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"outputs":[],"source":["# PERSON — Post-processing rules\n","# Suffixes allowed to merge into PERSON spans (handled via Span logic)\n","PERSON_SUFFIXES = {\"jr.\", \"sr.\", \"ii\", \"iii\", \"iv\", \"v\"}\n","\n","# Tokens that should invalidate a PERSON candidate if included\n","NON_PERSON_TOKENS = {\n","    \"Chief\", \"President\", \"Director\", \"Chairman\", \"Officer\",\n","    \"Executive\", \"Committee\", \"Board\", \"Company\",\n","    \"Inc\", \"Inc.\", \"Corp\", \"Corp.\", \"Corporation\",\n","    \"LLC\", \"L.L.C.\", \"Ltd\", \"Ltd.\",\n","}\n","\n","# Structural phrases that should never resolve to PERSON\n","PERSON_BLOCKLIST = {\n","    \"Business Conduct\",\n","    \"Business Experience\",\n","    \"Additional Information\",\n","}\n","\n","# TITLE — Canonical vocabulary\n","# Used for EntityRuler rules + checks\n","TITLE_TERMS = [\n","    \"Chief Executive Officer\", \"CEO\",\n","    \"Chief Financial Officer\", \"CFO\",\n","    \"Chief Operating Officer\", \"COO\",\n","    \"Chief Accounting Officer\", \"CAO\",\n","    \"President\", \"Vice President\",\n","    \"Chairman\", \"Chair\",\n","    \"Director\", \"Lead Director\",\n","    \"General Counsel\", \"Secretary\", \"Treasurer\",\n","]\n","\n","# Longest-first prevents partial matches (e.g., CEO inside CEO/CFO)\n","TITLE_TERMS_SORTED = sorted(TITLE_TERMS, key=len, reverse=True)\n","\n","# ORG — Structural constraints\n","ORG_SUFFIXES = [\n","    \"Inc\", \"Inc.\", \"Corp\", \"Corp.\", \"Corporation\",\n","    \"LLC\", \"L.L.C.\", \"LP\", \"L.P.\", \"Ltd\", \"Ltd.\",\n","    \"PLC\", \"P.L.C.\", \"Limited\"\n","]\n","\n","# Exact phrases that should never survive ORG filtering\n","ORG_STOP_EXACT = {\n","    \"company\",\n","    \"the company\",\n","    \"“company\",\n","    \"\\\"company\",\n","}\n","\n","# Substrings that invalidate ORG candidates\n","ORG_STOP_CONTAINS = {\n","    \"delaware corporation\",\n","    \"a delaware corporation\",\n","}\n","\n","# MONEY — Context classification\n","# Scale words spaCy rules are allowed to treat as money-like\n","MONEY_SCALES = {\"thousand\", \"million\", \"billion\"}\n","\n","# Context words used to classify MONEY_CANDIDATE -> REVENUE_MONEY\n","REVENUE_CONTEXT_TERMS = {\n","    \"revenue\",\n","    \"net sales\",\n","    \"sales\",\n","    \"income\",\n","    \"net income\",\n","    \"net loss\",\n","    \"turnover\",\n","    \"totaled\",\n","}\n"]},{"cell_type":"markdown","id":"5250f4ba","metadata":{"id":"5250f4ba"},"source":["### 3. Model Loading & Pipeline Assembly\n","\n","This section is responsible for:\n","- loading one or more spaCy pipelines\n","- attaching rule-based components (EntityRuler)\n","- clearly separating **baseline models** from **augmented pipelines**\n","\n","At this stage:\n","- a lightweight baseline model for fast iteration\n","- an augmented rule-first pipeline for controlled extraction\n","\n","No entity logic lives here: only pipeline configuration.\n","\n","#### Pipelines\n","- **Baseline pipelines**\n","  - `en_core_web_sm`\n","  - `en_core_web_trf`\n","  - used as reference points for native spaCy behavior\n","\n","- **Rule-augmented pipelines**\n","  - `en_core_web_sm` + EntityRuler components\n","  - `en_core_web_trf` + EntityRuler components\n","  - rule components inserted *before* `ner`\n","  - rule patterns defined in the Entity Modules section `(TITLE, MONEY_CANDIDATE, ORG_CANDIDATE)`\n","\n","#### Design Notes\n","- Pipelines are built via small, composable factory functions\n","- No global mutation of spaCy pipelines (build fresh per call)\n","- Multiple pipelines may coexist in memory for side-by-side evaluation\n","- Rules are attached consistently across `sm` and `trf` so comparisons are apples-to-apples\n"]},{"cell_type":"code","execution_count":6,"id":"0210f5ab","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0210f5ab","executionInfo":{"status":"ok","timestamp":1767372432724,"user_tz":360,"elapsed":13471,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"bd9c4930-2c61-413d-8a5e-13ce0ea1d90c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pipelines:\n","  sm_base: core_web_sm | pipes=['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n","  sm_aug: core_web_sm | pipes=['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'entity_ruler', 'ner']\n","  trf_base: core_web_trf | pipes=['transformer', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n","  trf_aug: core_web_trf | pipes=['transformer', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'entity_ruler', 'ner']\n"]}],"source":["# Section 3: Model Loading & Pipeline Assembly\n","MODEL_NAMES = {\n","    \"sm\": \"en_core_web_sm\",\n","    \"trf\": \"en_core_web_trf\",\n","}\n","\n","def _try_load(model_name: str) -> spacy.language.Language | None:\n","    \"\"\"\n","    Try to load a spaCy pipeline. Return None if not installed.\n","    \"\"\"\n","    try:\n","        return spacy.load(model_name)\n","    except OSError as e:\n","        print(f\"[WARN] Could not load '{model_name}'. Is it installed? ({e})\")\n","        return None\n","\n","\n","def load_base_pipeline(model_name: str) -> spacy.language.Language | None:\n","    \"\"\"\n","    Load a baseline spaCy pipeline (no custom rules). Returns None if unavailable.\n","    \"\"\"\n","    return _try_load(model_name)\n","\n","\n","def load_augmented_pipeline(\n","    model_name: str,\n","    ruler_name: str = \"entity_ruler\",\n","    before_component: str = \"ner\",\n",") -> spacy.language.Language | None:\n","    \"\"\"\n","    Load a spaCy pipeline and insert an *empty* EntityRuler before NER.\n","    Patterns are added later by the Entity Modules section.\n","    Returns None if the model is unavailable.\n","    \"\"\"\n","    nlp = _try_load(model_name)\n","    if nlp is None:\n","        return None\n","\n","    # Defensive: avoid reusing a prior ruler in the same runtime\n","    if ruler_name in nlp.pipe_names:\n","        nlp.remove_pipe(ruler_name)\n","\n","    if before_component in nlp.pipe_names:\n","        nlp.add_pipe(ruler_name, before=before_component)\n","    else:\n","        nlp.add_pipe(ruler_name)\n","\n","    return nlp\n","\n","\n","def load_pipelines(model_names: dict = MODEL_NAMES) -> dict:\n","    \"\"\"\n","    Return baseline + augmented pipelines for sm and trf.\n","    Any missing models will be skipped (value = None).\n","    \"\"\"\n","    sm_base = load_base_pipeline(model_names[\"sm\"])\n","    sm_aug  = load_augmented_pipeline(model_names[\"sm\"])\n","\n","    trf_base = load_base_pipeline(model_names[\"trf\"])\n","    trf_aug  = load_augmented_pipeline(model_names[\"trf\"])\n","\n","    return {\n","        \"sm_base\": sm_base,\n","        \"sm_aug\": sm_aug,\n","        \"trf_base\": trf_base,\n","        \"trf_aug\": trf_aug,\n","    }\n","\n","\n","def describe_pipelines(pipes: dict) -> None:\n","    \"\"\"\n","    Print a quick summary of which pipelines loaded and their components.\n","    \"\"\"\n","    print(\"Loaded pipelines:\")\n","    for key, nlp in pipes.items():\n","        if nlp is None:\n","            print(f\"  {key}: <not loaded>\")\n","        else:\n","            name = nlp.meta.get(\"name\", \"unknown\")\n","            print(f\"  {key}: {name} | pipes={nlp.pipe_names}\")\n","\n","\n","# Build pipelines now (rules get attached later)\n","pipelines = load_pipelines()\n","describe_pipelines(pipelines)\n"]},{"cell_type":"markdown","source":["### 4. Entity Modules (Rule Components)\n","\n","This section defines **rule modules per entity**, without running any documents yet.\n","\n","Goals:\n","- Keep rules **modular** `(TITLE, MONEY_CANDIDATE, ORG_CANDIDATE)`\n","- Attach rules consistently to both augmented pipelines (`sm_aug`, `trf_aug`)\n","- Avoid overengineering: rules should target known SEC patterns and labeling rules\n","\n","Outputs:\n","- Functions that attach patterns to a pipeline's `entity_ruler`\n","- No model mutation outside of `*_aug` pipelines\n","- Rules are additive and can be expanded later\n"],"metadata":{"id":"z7XCyVl3D-8B"},"id":"z7XCyVl3D-8B"},{"cell_type":"code","source":["# Section 4: Entity Modules (Rule Components)\n","from spacy.tokens import Span\n","from spacy.language import Language\n","\n","# Candidate labels should NOT live in doc.ents (finals only)\n","CANDIDATE_LABEL_TO_SPANKEY = {\n","    \"MONEY_CANDIDATE\": \"money_candidates\",\n","    \"ORG_CANDIDATE\": \"org_candidates\",\n","}\n","\n","def _get_ruler(nlp, ruler_name: str = \"entity_ruler\") -> EntityRuler:\n","    \"\"\"\n","    Fetch the EntityRuler from an augmented pipeline.\n","    Raises a clear error if you're accidentally using a base pipeline.\n","    \"\"\"\n","    if ruler_name not in nlp.pipe_names:\n","        raise ValueError(\n","            f\"Pipeline has no '{ruler_name}'. Did you mean to use an *_aug pipeline?\\n\"\n","            f\"pipes={nlp.pipe_names}\"\n","        )\n","    return nlp.get_pipe(ruler_name)\n","\n","\n","@Language.component(\"candidate_siphon\")\n","def candidate_siphon(doc):\n","    \"\"\"\n","    Move *_CANDIDATE entities into doc.spans[...] and remove them from doc.ents.\n","\n","    - Keeps offsets intact\n","    - Does not normalize text\n","    - Ensures candidates never pollute downstream scoring that reads doc.ents\n","    \"\"\"\n","    # Ensure span keys exist\n","    for span_key in CANDIDATE_LABEL_TO_SPANKEY.values():\n","        doc.spans.setdefault(span_key, [])\n","\n","    kept = []\n","    for ent in doc.ents:\n","        span_key = CANDIDATE_LABEL_TO_SPANKEY.get(ent.label_)\n","        if span_key:\n","            doc.spans.setdefault(span_key, [])\n","            doc.spans[span_key].append(SpacySpan(doc, ent.start, ent.end, label=ent.label_))\n","        else:\n","            kept.append(ent)\n","\n","    doc.ents = kept\n","    return doc\n","\n","FINAL_LABELS_BLOCK_FROM_NER = {\"MONEY\", \"ORG\"}\n","\n","@Language.component(\"strip_ner_money_org\")\n","def strip_ner_money_org(doc):\n","    \"\"\"\n","    Remove NER-produced MONEY/ORG from doc.ents in augmented pipelines.\n","    We will later add back final MONEY/ORG via our own candidate->final logic.\n","    \"\"\"\n","    doc.ents = [ent for ent in doc.ents if ent.label_ not in FINAL_LABELS_BLOCK_FROM_NER]\n","    return doc\n","\n","\n","def attach_strip_ner_money_org(\n","    nlp,\n","    *,\n","    name: str = \"strip_ner_money_org\",\n","    after: str = \"ner\",\n",") -> None:\n","    if name in nlp.pipe_names:\n","        nlp.remove_pipe(name)\n","    if after in nlp.pipe_names:\n","        nlp.add_pipe(name, after=after)\n","    else:\n","        nlp.add_pipe(name)  # fallback\n","\n","\n","def attach_candidate_siphon(\n","    nlp,\n","    *,\n","    name: str = \"candidate_siphon\",\n","    after: str = \"entity_ruler\",\n","    before: str = \"ner\",\n",") -> None:\n","    \"\"\"\n","    Attach candidate siphon component so that:\n","      entity_ruler -> candidate_siphon -> ner\n","    \"\"\"\n","    if name in nlp.pipe_names:\n","        nlp.remove_pipe(name)\n","\n","    if after in nlp.pipe_names:\n","        nlp.add_pipe(name, after=after)\n","    elif before in nlp.pipe_names:\n","        nlp.add_pipe(name, before=before)\n","    else:\n","        nlp.add_pipe(name)\n","\n","\n","# 4.1 TITLE rules\n","def add_title_rules(nlp) -> None:\n","    ruler = _get_ruler(nlp)\n","\n","    patterns = []\n","    for term in TITLE_TERMS_SORTED:\n","        patterns.append({\"label\": \"TITLE\", \"pattern\": [{\"LOWER\": t.lower()} for t in term.split()]})\n","\n","    patterns.append({\n","        \"label\": \"TITLE\",\n","        \"pattern\": [\n","            {\"LOWER\": \"chief\"},\n","            {\"IS_TITLE\": True, \"OP\": \"+\"},\n","            {\"LOWER\": \"officer\"},\n","        ],\n","    })\n","\n","    patterns.append({\n","        \"label\": \"TITLE\",\n","        \"pattern\": [\n","            {\"LOWER\": \"chief\"},\n","            {\"IS_TITLE\": True, \"OP\": \"+\"},\n","            {\"TEXT\": \"\\n\", \"OP\": \"?\"},\n","            {\"LOWER\": \"officer\"},\n","        ],\n","    })\n","\n","    patterns.append({\n","        \"label\": \"TITLE\",\n","        \"pattern\": [\n","            {\"IS_TITLE\": True, \"OP\": \"+\"},\n","            {\"LOWER\": \"officer\"},\n","        ],\n","    })\n","\n","    ruler.add_patterns(patterns)\n","\n","\n","# 4.2 MONEY_CANDIDATE rules\n","def add_money_candidate_rules(nlp) -> None:\n","    ruler = _get_ruler(nlp)\n","\n","    patterns = [\n","        {\"label\": \"MONEY_CANDIDATE\", \"pattern\": [{\"TEXT\": {\"REGEX\": r\"^\\$[\\d,]+(\\.\\d+)?$\"}}]},\n","        {\"label\": \"MONEY_CANDIDATE\", \"pattern\": [\n","            {\"TEXT\": \"$\"},\n","            {\"TEXT\": {\"REGEX\": r\"^[\\d,]+(\\.\\d+)?$\"}},\n","        ]},\n","        {\"label\": \"MONEY_CANDIDATE\", \"pattern\": [\n","            {\"LIKE_NUM\": True},\n","            {\"LOWER\": {\"IN\": sorted(MONEY_SCALES)}},\n","        ]},\n","        {\"label\": \"MONEY_CANDIDATE\", \"pattern\": [{\"TEXT\": {\"REGEX\": r\"^\\(\\$?[\\d,]+(\\.\\d+)?\\)$\"}}]},\n","        {\"label\": \"MONEY_CANDIDATE\", \"pattern\": [{\"TEXT\": {\"REGEX\": r\"^[\\d]+(\\.\\d+)?[mMbB]$\"}}]},\n","        {\"label\": \"MONEY_CANDIDATE\", \"pattern\": [\n","            {\"TEXT\": \"$\"},\n","            {\"TEXT\": {\"REGEX\": r\"^[\\d]+(\\.\\d+)?$\"}},\n","            {\"LOWER\": {\"IN\": [\"m\", \"b\"]}},\n","        ]},\n","        {\"label\": \"MONEY_CANDIDATE\", \"pattern\": [\n","            {\"TEXT\": \"$\"},\n","            {\"TEXT\": {\"REGEX\": r\"^[\\d]+(\\.\\d+)?[mMbB]\\.?$\"}},\n","        ]},\n","        {\"label\": \"MONEY_CANDIDATE\", \"pattern\": [\n","            {\"LIKE_NUM\": True},\n","            {\"TEXT\": \"(\"},\n","            {\"LOWER\": \"in\", \"OP\": \"?\"},\n","            {\"LOWER\": \"thousands\"},\n","            {\"TEXT\": \")\"},\n","        ]},\n","        {\"label\": \"MONEY_CANDIDATE\", \"pattern\": [\n","            {\"TEXT\": \"$\"},\n","            {\"LIKE_NUM\": True},\n","            {\"TEXT\": \"(\"},\n","            {\"LOWER\": \"in\", \"OP\": \"?\"},\n","            {\"LOWER\": \"thousands\"},\n","            {\"TEXT\": \")\"},\n","        ]},\n","    ]\n","\n","    ruler.add_patterns(patterns)\n","\n","\n","# 4.3 ORG_CANDIDATE rules\n","def add_org_candidate_rules(nlp) -> None:\n","    ruler = _get_ruler(nlp)\n","\n","    suffixes = [s.lower() for s in ORG_SUFFIXES]\n","\n","    patterns = [\n","        {\"label\": \"ORG_CANDIDATE\", \"pattern\": [\n","            {\"IS_TITLE\": True, \"OP\": \"+\"},\n","            {\"TEXT\": \",\", \"OP\": \"?\"},\n","            {\"LOWER\": {\"IN\": suffixes}},\n","        ]},\n","        {\"label\": \"ORG_CANDIDATE\", \"pattern\": [\n","            {\"IS_TITLE\": True, \"OP\": \"+\"},\n","            {\"TEXT\": \",\", \"OP\": \"?\"},\n","            {\"TEXT\": {\"REGEX\": r\"^([A-Za-z]\\.){2,}[A-Za-z]\\.?$\"}},\n","        ]},\n","        {\"label\": \"ORG_CANDIDATE\", \"pattern\": [\n","            {\"LOWER\": \"doing\"},\n","            {\"LOWER\": \"business\"},\n","            {\"LOWER\": \"as\"},\n","            {\"IS_TITLE\": True, \"OP\": \"+\"},\n","        ]},\n","    ]\n","\n","    ruler.add_patterns(patterns)\n","\n","\n","# Attach all modules (+ siphon) to augmented pipelines\n","def attach_entity_modules(pipelines_dict: dict) -> None:\n","    for key, nlp in pipelines_dict.items():\n","        if nlp is None or not key.endswith(\"_aug\"):\n","            continue\n","\n","        add_title_rules(nlp)\n","        add_money_candidate_rules(nlp)\n","        add_org_candidate_rules(nlp)\n","\n","        attach_candidate_siphon(nlp)          # after entity_ruler, before ner\n","        attach_strip_ner_money_org(nlp)       # after ner\n","\n","attach_entity_modules(pipelines)\n","\n","print(\"Entity modules attached to augmented pipelines:\")\n","for k, nlp in pipelines.items():\n","    if nlp is None:\n","        continue\n","    if k.endswith(\"_aug\"):\n","        ruler = nlp.get_pipe(\"entity_ruler\")\n","        print(f\"  {k}: ruler patterns={len(ruler.patterns)} | pipes={nlp.pipe_names}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xpZUPWsCEQ_Z","executionInfo":{"status":"ok","timestamp":1767372432777,"user_tz":360,"elapsed":47,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"fffd7c48-02c3-46a9-cf0c-f588a6d05ed5"},"id":"xpZUPWsCEQ_Z","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Entity modules attached to augmented pipelines:\n","  sm_aug: ruler patterns=32 | pipes=['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'entity_ruler', 'candidate_siphon', 'ner', 'strip_ner_money_org']\n","  trf_aug: ruler patterns=32 | pipes=['transformer', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'entity_ruler', 'candidate_siphon', 'ner', 'strip_ner_money_org']\n"]}]},{"cell_type":"markdown","source":["### 5. Shared Helpers (Printing, Selection, Normalization)\n","\n","This section provides small, reusable helpers used across all experiments and both pipelines.\n","\n","Goals:\n","- Keep evaluation tooling consistent across `sm` and `trf`\n","- Support “twin mode” output:\n","  - **machine-friendly**: `(start, end, label)` spans\n","  - **human-friendly**: readable grouped summaries by label\n","- Standardize candidate selection to reduce overlap noise:\n","  - prefer-longest selection for *_CANDIDATE entities\n","- Standardize light normalization where appropriate:\n","  - punctuation trimming for display (e.g., `$3.1M.` -> `$3.1M`)\n","  - avoid destructive normalization that changes offsets\n","\n","Key utilities included:\n","- `run_suite(nlp, texts, ...)`: run a probe list through a pipeline with consistent output controls\n","- `iter_ents(doc)`: return machine-friendly entity tuples `(start, end, label)`\n","- `summarize_ents(doc)`: grouped human-friendly entity view by label\n","- `prefer_longest(doc, label)`: select non-overlapping candidate spans by length\n","- `normalize_view(text)`: optional *display-only* cleanup (never used for offsets)\n","\n","Design notes:\n","- Offsets are always measured against the original doc text\n","- All normalization is “view-only” unless explicitly stated otherwise\n","- Helpers should be model-agnostic and reusable for future testing notebooks\n"],"metadata":{"id":"HWkO75-oG4v9"},"id":"HWkO75-oG4v9"},{"cell_type":"code","source":["# 5. Shared Helpers (Printing, Selection, Normalization)\n","\n","# Display-only normalization\n","def normalize_view(text: str) -> str:\n","    \"\"\"\n","    Display-only cleanup. NEVER used for offsets.\n","    Current behavior: strip trailing punctuation (e.g., \"$3.1M.\" -> \"$3.1M\").\n","    \"\"\"\n","    return text.rstrip(string.punctuation)\n","\n","# Machine-friendly entities\n","def iter_ents(doc) -> List[Tuple[int, int, str]]:\n","    \"\"\"\n","    Machine-friendly entities: (start_char, end_char, label)\n","    Offsets always reference doc.text.\n","    \"\"\"\n","    return [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n","\n","# Human-friendly summary\n","def summarize_ents(\n","    doc,\n","    *,\n","    normalize: bool = True\n",") -> Dict[str, List[Tuple[int, int, str]]]:\n","    \"\"\"\n","    Grouped human-friendly view by label.\n","\n","    Returns:\n","      {\n","        \"PERSON\": [(start, end, \"John Smith\"), ...],\n","        \"TITLE\":  [(start, end, \"Chief Executive Officer\"), ...],\n","      }\n","\n","    Text is optional display-normalized (never used for offsets).\n","    \"\"\"\n","    grouped = defaultdict(list)\n","    for start, end, label in iter_ents(doc):\n","        raw = doc.text[start:end]\n","        view = normalize_view(raw) if normalize else raw\n","        grouped[label].append((start, end, view))\n","    return dict(grouped)\n","\n","# Longest-span candidate selection\n","def prefer_longest(\n","    doc,\n","    label: str,\n","    *,\n","    normalize: bool = True\n",") -> List[Tuple[int, int, str]]:\n","    \"\"\"\n","    Select non-overlapping spans of a given label, preferring longest spans.\n","\n","    Returns a list of (start, end, text_view) tuples (display text optional).\n","    Offsets remain authoritative.\n","    \"\"\"\n","    spans = [(ent.start_char, ent.end_char) for ent in doc.ents if ent.label_ == label]\n","    spans = sorted(spans, key=lambda x: (x[0], -(x[1] - x[0])))\n","\n","    kept: List[Tuple[int, int]] = []\n","    for s, e in spans:\n","        if any(not (e <= ks or s >= ke) for ks, ke in kept):\n","            continue\n","        kept.append((s, e))\n","\n","    out = []\n","    for s, e in kept:\n","        raw = doc.text[s:e]\n","        view = normalize_view(raw) if normalize else raw\n","        out.append((s, e, view))\n","    return out\n","\n","# Run harness for probe lists\n","def run_suite(\n","    nlp,\n","    texts: List[str],\n","    *,\n","    header: Optional[str] = None,\n","    show_tokens: bool = False,\n","    show_machine: bool = False,\n","    show_summary: bool = True,\n","    normalize: bool = True\n",") -> None:\n","    \"\"\"\n","    Run a list of probe texts through an nlp pipeline and print consistent output.\n","\n","    Controls:\n","    - show_tokens: print token list\n","    - show_machine: print iter_ents(doc)\n","    - show_summary: print summarize_ents(doc) (grouped by label)\n","    - normalize: whether summary uses normalize_view()\n","    \"\"\"\n","    if header:\n","        print(f\"=== {header} ===\")\n","\n","    for text in texts:\n","        doc = nlp(text)\n","        print(\"\\nTEXT:\", text)\n","\n","        if show_tokens:\n","            print(\"TOKENS:\", [t.text for t in doc])\n","\n","        if show_machine:\n","            print(\"ENTS_MACHINE:\", iter_ents(doc))\n","\n","        if show_summary:\n","            summary = summarize_ents(doc, normalize=normalize)\n","            print(\"ENTS_SUMMARY:\", summary)\n","\n","def doc_inventory(\n","    doc,\n","    *,\n","    normalize: bool = True\n",") -> Dict[str, List[Tuple[int, int, str]]]:\n","    \"\"\"\n","    Master entity inventory for a document.\n","\n","    Returns:\n","      {\n","        \"PERSON\": [(start, end, \"John Q. Smith\"), ...],\n","        \"TITLE\":  [(start, end, \"Chief Financial Officer\"), ...],\n","        \"MONEY\":  [(start, end, \"$2.4 million\"), ...],\n","      }\n","\n","    - Offsets are always authoritative\n","    - Text is optionally display-normalized\n","    \"\"\"\n","    inventory = defaultdict(list)\n","\n","    for ent in doc.ents:\n","        start = ent.start_char\n","        end = ent.end_char\n","        raw = doc.text[start:end]\n","        view = normalize_view(raw) if normalize else raw\n","        inventory[ent.label_].append((start, end, view))\n","\n","    return dict(inventory)\n","\n","def print_doc_inventory(\n","    doc,\n","    *,\n","    normalize: bool = True\n",") -> None:\n","    \"\"\"\n","    Human-friendly print of doc_inventory().\n","    \"\"\"\n","    inv = doc_inventory(doc, normalize=normalize)\n","    print(\"ENTITY INVENTORY:\")\n","    for label in sorted(inv):\n","        print(f\"  {label}:\")\n","        for start, end, text in inv[label]:\n","            print(f\"    ({start}, {end}) → {text}\")\n","\n","def print_entity_provenance(doc) -> None:\n","    print(\"ENTS (final):\", [(e.text, e.label_, e.start_char, e.end_char) for e in doc.ents])\n","\n","    for key in [\"money_candidates\", \"org_candidates\"]:\n","        spans = doc.spans.get(key, [])\n","        print(f\"{key}:\", [(s.text, s.label_, s.start_char, s.end_char) for s in spans])\n","\n","\n"],"metadata":{"id":"uILtrtyvKQ-6","executionInfo":{"status":"ok","timestamp":1767372432828,"user_tz":360,"elapsed":31,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"uILtrtyvKQ-6","execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["6. Data loading + canonical doc objects\n","\n","This section loads raw SEC 10-K JSON filings and converts them into canonical document objects used throughout the notebook.\n","\n","Goals\n","- Create a consistent representation of each filing with section-scoped text fields used for extraction and scoring.\n","- Preserve metadata (filename, company, dates) for reporting and grouping results.\n","- Enforce evaluation scope:\n","  - Item 7 → MONEY only\n","  - Item 10 → PERSON / TITLE / ORG only\n","  - No cross-pollination across sections in scoring.\n","\n","Inputs\n","- Primary filing JSONs (raw SEC extraction)\n","  - Must contain text for item_7 and item_10 (or empty if missing).\n","-Gold annotation JSONs (*.json.gold.json)\n","  - Schema versioned; includes annotations[] with section-scoped offsets:\n","    - label, section, start, end, text\n","\n","Canonical objects\n","- We will define two lightweight container types:\n","  1. CanonicalFiling\n","    - `filename`\n","    - `company`\n","    - `filing_date`, `period_of_report` (if available)\n","    - `item_7_text` (string; may be empty)\n","    - `item_10_text` (string; may be empty)\n","  2. `DocBundle` (optional convenience object)\n","    - Holds processed spaCy docs for twin evaluation:\n","      - `item7_doc_sm`, `item7_doc_trf`\n","      - `item10_doc_sm`, `item10_doc_trf`\n","    - Also stores the raw section strings used to generate offsets.\n","\n","Design notes\n","- Offsets are always section-scoped (relative to `item_7_text` or `item_10_text`).\n","- spaCy docs are created directly from these canonical section strings (no concatenation).\n","- In augmented pipelines (*_aug):\n","  - candidate labels (`MONEY_CANDIDATE`, `ORG_CANDIDATE`) are stored in doc.spans[...]\n","  - NER-produced `MONEY` and `ORG` are stripped to prevent downstream eval pollution\n","  - final doc.ents contains only the remaining final labels (e.g., PERSON/TITLE), until candidate→final promotion is applied later.\n","\n","Output of Section 6\n","-  list of CanonicalFiling objects\n","- Loaders to:\n","  - load raw filings from disk\n","  - load matching gold files from disk\n","- Utilities to create DocBundles for downstream harness + scoring"],"metadata":{"id":"-375ho2aQlRj"},"id":"-375ho2aQlRj"},{"cell_type":"code","source":["# 6. Data loading + canonical doc objects\n","# Paths (reproducible)\n","def find_project_root(\n","    start: Path,\n","    *,\n","    markers: Tuple[str, ...] = (\"primary_data.json\", \"gold_annotations\", \"Notebooks\"),\n",") -> Path:\n","    \"\"\"\n","    Walk upward from `start` until we find a directory that looks like the project root.\n","    This makes the notebook robust across Jupyter/VSCode/cwd differences.\n","    \"\"\"\n","    start = start.resolve()\n","    for p in (start, *start.parents):\n","        hits = 0\n","        for m in markers:\n","            if (p / m).exists():\n","                hits += 1\n","        # A loose heuristic: if it has primary_data.json OR gold_annotations, it's likely root.\n","        if (p / \"primary_data.json\").exists() or (p / \"gold_annotations\").exists():\n","            return p\n","        # Or: if it has multiple markers, also accept\n","        if hits >= 2:\n","            return p\n","    # Fallback: just use start; callers can assert later\n","    return start\n","\n","# In notebooks, Path.cwd() is usually Notebooks/ but not always.\n","PROJECT_ROOT = find_project_root(Path.cwd())\n","DATA_PATH = PROJECT_ROOT / \"primary_data.json\"\n","GOLD_DIR = PROJECT_ROOT / \"gold_annotations\"\n","\n","\n","# Canonical containers\n","@dataclass(frozen=True)\n","class CanonicalFiling:\n","    \"\"\"\n","    Canonical, section-scoped text container for a single 10-K filing.\n","\n","    Notes:\n","    - item_7_text and item_10_text are the authoritative strings for offsets.\n","    - We do NOT concatenate sections; offsets remain section-scoped.\n","    \"\"\"\n","    filename: str\n","    company: str = \"\"\n","    filing_date: str = \"\"\n","    period_of_report: str = \"\"\n","    item_7_text: str = \"\"\n","    item_10_text: str = \"\"\n","\n","\n","@dataclass(frozen=True)\n","class GoldAnnotation:\n","    label: str\n","    section: str\n","    start: int\n","    end: int\n","    text: str\n","\n","\n","@dataclass(frozen=True)\n","class GoldDoc:\n","    \"\"\"\n","    Parsed gold template file (*.json.gold.json) matching schema_version=1.0 structure.\n","    Offsets are section-scoped.\n","    \"\"\"\n","    filename: str\n","    company: str = \"\"\n","    filing_date: str = \"\"\n","    period_of_report: str = \"\"\n","    notes: str = \"\"\n","    schema_version: str = \"1.0\"\n","    annotations: Tuple[GoldAnnotation, ...] = ()\n","\n","\n","@dataclass\n","class DocBundle:\n","    \"\"\"\n","    Convenience holder for twin-track docs per section.\n","\n","    We keep both baseline and augmented docs here so downstream harness/scoring can be\n","    standardized without recreating docs repeatedly.\n","    \"\"\"\n","    filing: CanonicalFiling\n","    gold: Optional[GoldDoc]\n","\n","    # Item 7 docs\n","    item7_sm_base: Optional[Any] = None\n","    item7_sm_aug: Optional[Any] = None\n","    item7_trf_base: Optional[Any] = None\n","    item7_trf_aug: Optional[Any] = None\n","\n","    # Item 10 docs\n","    item10_sm_base: Optional[Any] = None\n","    item10_sm_aug: Optional[Any] = None\n","    item10_trf_base: Optional[Any] = None\n","    item10_trf_aug: Optional[Any] = None\n","\n","\n","# Low-level JSON helpers\n","def _read_json(path: Path) -> Any:\n","    with path.open(\"r\", encoding=\"utf-8\") as f:\n","        return json.load(f)\n","\n","\n","def _safe_str(x: Any) -> str:\n","    return \"\" if x is None else str(x)\n","\n","\n","def _extract_section_text(raw: Dict[str, Any], section: str) -> str:\n","    \"\"\"\n","    Best-effort extraction of section text from raw filing JSON.\n","\n","    Supports common shapes:\n","    - raw[\"item_7\"] / raw[\"item_10\"] as strings\n","    - raw[\"item_7\"][\"text\"] / raw[\"item_10\"][\"text\"]\n","    - raw[\"sections\"][\"item_7\"] / raw[\"sections\"][\"item_10\"]\n","    - raw[\"items\"][\"item_7\"] / raw[\"items\"][\"item_10\"]\n","    \"\"\"\n","    # Direct\n","    if section in raw:\n","        v = raw.get(section)\n","        if isinstance(v, str):\n","            return v\n","        if isinstance(v, dict):\n","            if isinstance(v.get(\"text\"), str):\n","                return v[\"text\"]\n","            if isinstance(v.get(\"content\"), str):\n","                return v[\"content\"]\n","\n","    # Nested common containers\n","    for container_key in (\"sections\", \"items\", \"extracted\", \"extraction\"):\n","        cont = raw.get(container_key)\n","        if isinstance(cont, dict) and section in cont:\n","            v = cont.get(section)\n","            if isinstance(v, str):\n","                return v\n","            if isinstance(v, dict):\n","                if isinstance(v.get(\"text\"), str):\n","                    return v[\"text\"]\n","                if isinstance(v.get(\"content\"), str):\n","                    return v[\"content\"]\n","\n","    return \"\"\n","\n","# Parse raw filing record(s)\n","def parse_filing_record(raw: Dict[str, Any], *, filename_fallback: str = \"\") -> CanonicalFiling:\n","    \"\"\"\n","    Parse a single filing dict (as stored inside primary_data.json) -> CanonicalFiling.\n","    \"\"\"\n","    filename = raw.get(\"filename\") or filename_fallback\n","    company = _safe_str(raw.get(\"company\") or raw.get(\"company_name\") or raw.get(\"registrant_name\") or \"\")\n","    filing_date = _safe_str(raw.get(\"filing_date\") or raw.get(\"filed_as_of_date\") or raw.get(\"filed\") or \"\")\n","    period_of_report = _safe_str(raw.get(\"period_of_report\") or raw.get(\"period\") or raw.get(\"report_period\") or \"\")\n","\n","    item_7_text = _extract_section_text(raw, \"item_7\")\n","    item_10_text = _extract_section_text(raw, \"item_10\")\n","\n","    return CanonicalFiling(\n","        filename=str(filename),\n","        company=company,\n","        filing_date=filing_date,\n","        period_of_report=period_of_report,\n","        item_7_text=item_7_text or \"\",\n","        item_10_text=item_10_text or \"\",\n","    )\n","\n","\n","def load_filings_from_primary_data(primary_data_path: str | Path = DATA_PATH) -> List[CanonicalFiling]:\n","    \"\"\"\n","    primary_data.json loader for your current setup.\n","\n","    Expected shapes supported:\n","    1) Dict keyed by filename -> filing dict\n","    2) List of filing dicts (each with filename field)\n","    \"\"\"\n","    primary_data_path = Path(primary_data_path)\n","    raw = _read_json(primary_data_path)\n","\n","    out: List[CanonicalFiling] = []\n","    if isinstance(raw, dict):\n","        # Common: { \"1066...json\": { ...filing... }, ... }\n","        for k, v in raw.items():\n","            if isinstance(v, dict):\n","                out.append(parse_filing_record(v, filename_fallback=str(k)))\n","    elif isinstance(raw, list):\n","        for v in raw:\n","            if isinstance(v, dict):\n","                out.append(parse_filing_record(v))\n","    else:\n","        raise TypeError(f\"Unsupported primary_data.json shape: {type(raw)}\")\n","\n","    return out\n","\n","\n","# Parse gold JSON -> GoldDoc\n","def parse_gold_json(path: Path) -> GoldDoc:\n","    raw = _read_json(path)\n","\n","    anns: List[GoldAnnotation] = []\n","    for a in (raw.get(\"annotations\", []) or []):\n","        anns.append(\n","            GoldAnnotation(\n","                label=_safe_str(a.get(\"label\")),\n","                section=_safe_str(a.get(\"section\")),\n","                start=int(a.get(\"start\")),\n","                end=int(a.get(\"end\")),\n","                text=_safe_str(a.get(\"text\")),\n","            )\n","        )\n","\n","    return GoldDoc(\n","        filename=_safe_str(raw.get(\"filename\") or \"\"),\n","        company=_safe_str(raw.get(\"company\") or \"\"),\n","        filing_date=_safe_str(raw.get(\"filing_date\") or \"\"),\n","        period_of_report=_safe_str(raw.get(\"period_of_report\") or \"\"),\n","        notes=_safe_str(raw.get(\"notes\") or \"\"),\n","        schema_version=_safe_str(raw.get(\"schema_version\") or \"1.0\"),\n","        annotations=tuple(anns),\n","    )\n","\n","\n","def load_gold_from_dir(gold_dir: str | Path = GOLD_DIR) -> Dict[str, GoldDoc]:\n","    \"\"\"\n","    Returns mapping: base filename (e.g., '1017655_10K_2020_...json') -> GoldDoc\n","    \"\"\"\n","    gold_dir = Path(gold_dir)\n","    paths = sorted(gold_dir.glob(\"*.json.gold.json\"))\n","\n","    out: Dict[str, GoldDoc] = {}\n","    for p in paths:\n","        gd = parse_gold_json(p)\n","        # Gold files store original filename inside; trust it when available.\n","        key = gd.filename or p.name.replace(\".gold.json\", \"\")\n","        out[key] = gd\n","\n","    return out\n","\n","# Gold alignment validator\n","def validate_gold_offsets(\n","    filing: CanonicalFiling,\n","    gold: GoldDoc,\n","    *,\n","    max_errors: int = 10,\n",") -> List[str]:\n","    \"\"\"\n","    Validates that gold annotation substrings match the provided 'text' field.\n","    Returns a list of human-readable error strings (empty list means OK).\n","    \"\"\"\n","    section_text_map = {\n","        \"item_7\": filing.item_7_text,\n","        \"item_10\": filing.item_10_text,\n","    }\n","\n","    errors: List[str] = []\n","    for i, ann in enumerate(gold.annotations):\n","        sec_text = section_text_map.get(ann.section, \"\")\n","        if not sec_text:\n","            errors.append(f\"[{i}] Missing section text for {ann.section} (filing={filing.filename})\")\n","            if len(errors) >= max_errors:\n","                break\n","            continue\n","\n","        if ann.start < 0 or ann.end > len(sec_text) or ann.start >= ann.end:\n","            errors.append(\n","                f\"[{i}] Bad span bounds {ann.start}:{ann.end} for {ann.section} \"\n","                f\"(len={len(sec_text)}) text={ann.text!r}\"\n","            )\n","            if len(errors) >= max_errors:\n","                break\n","            continue\n","\n","        slice_text = sec_text[ann.start:ann.end]\n","        if slice_text != ann.text:\n","            errors.append(\n","                f\"[{i}] Text mismatch in {ann.section} {ann.start}:{ann.end}\\n\"\n","                f\"  gold_text:  {ann.text!r}\\n\"\n","                f\"  slice_text: {slice_text!r}\"\n","            )\n","            if len(errors) >= max_errors:\n","                break\n","\n","    return errors\n","\n","# Build DocBundle (twin-track docs)\n","def make_doc_bundle(\n","    filing: CanonicalFiling,\n","    gold: Optional[GoldDoc],\n","    pipelines: dict,\n",") -> DocBundle:\n","    \"\"\"\n","    Create section-scoped spaCy docs for both baseline and augmented pipelines.\n","    This is intentionally \"dumb\": it just runs text through each loaded pipeline.\n","    \"\"\"\n","    b = DocBundle(filing=filing, gold=gold)\n","\n","    # Item 7\n","    text7 = filing.item_7_text or \"\"\n","    if pipelines.get(\"sm_base\") is not None:\n","        b.item7_sm_base = pipelines[\"sm_base\"](text7)\n","    if pipelines.get(\"sm_aug\") is not None:\n","        b.item7_sm_aug = pipelines[\"sm_aug\"](text7)\n","    if pipelines.get(\"trf_base\") is not None:\n","        b.item7_trf_base = pipelines[\"trf_base\"](text7)\n","    if pipelines.get(\"trf_aug\") is not None:\n","        b.item7_trf_aug = pipelines[\"trf_aug\"](text7)\n","\n","    # Item 10\n","    text10 = filing.item_10_text or \"\"\n","    if pipelines.get(\"sm_base\") is not None:\n","        b.item10_sm_base = pipelines[\"sm_base\"](text10)\n","    if pipelines.get(\"sm_aug\") is not None:\n","        b.item10_sm_aug = pipelines[\"sm_aug\"](text10)\n","    if pipelines.get(\"trf_base\") is not None:\n","        b.item10_trf_base = pipelines[\"trf_base\"](text10)\n","    if pipelines.get(\"trf_aug\") is not None:\n","        b.item10_trf_aug = pipelines[\"trf_aug\"](text10)\n","\n","    return b\n","\n","\n","def build_doc_bundles(\n","    filings: List[CanonicalFiling],\n","    gold_map: Dict[str, GoldDoc],\n","    pipelines: dict,\n",") -> List[DocBundle]:\n","    \"\"\"\n","    Match filings to gold (by filename), build DocBundles.\n","    \"\"\"\n","    bundles: List[DocBundle] = []\n","    for f in filings:\n","        g = gold_map.get(f.filename)\n","        bundles.append(make_doc_bundle(f, g, pipelines))\n","    return bundles\n","\n","# Suggested usage in the notebook\n","#filings = load_filings_from_primary_data(DATA_PATH)\n","# gold_map = load_gold_from_dir(GOLD_DIR)\n","# bundles = build_doc_bundles(filings, gold_map, pipelines)\n","\n","# (Optional) quick gold sanity check on only the ones that have gold:\n","# for b in bundles:\n","#     if b.gold:\n","#         errs = validate_gold_offsets(b.filing, b.gold, max_errors=3)\n","#         if errs:\n","#             print(\"----\", b.filing.filename)\n","#             print(\"\\n\".join(errs))\n"],"metadata":{"id":"wZEXY7Z4TqPj","executionInfo":{"status":"ok","timestamp":1767372432881,"user_tz":360,"elapsed":54,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"wZEXY7Z4TqPj","execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["7. Gold Parsing + Alignment Validator\n","\n","This section defines how spaCy predictions are aligned against gold annotations for evaluation. The purpose is measurement only:\n","- no training\n","- no rule tuning\n","- no feedback into the pipeline\n","\n","All alignment is performed post-extraction using immutable `DocBundle` objects."],"metadata":{"id":"b_86HlSTa_84"},"id":"b_86HlSTa_84"},{"cell_type":"code","source":["# Section 7: Alignment primitives\n","SpanBounds = Tuple[int, int]  # (start, end)\n","\n","@dataclass(frozen=True)\n","class PredictedSpan:\n","    \"\"\"\n","    Normalized prediction span used for alignment.\n","    \"\"\"\n","    label: str\n","    section: str\n","    start: int\n","    end: int\n","\n","\n","@dataclass(frozen=True)\n","class GoldSpan:\n","    \"\"\"\n","    Normalized gold span used for alignment.\n","    \"\"\"\n","    label: str\n","    section: str\n","    start: int\n","    end: int\n","\n","\n","@dataclass\n","class AlignmentResult:\n","    \"\"\"\n","    Result container for a single alignment pass.\n","    \"\"\"\n","    true_positives: List[Tuple[GoldSpan, PredictedSpan]]\n","    false_negatives: List[GoldSpan]\n","    false_positives: List[PredictedSpan]\n"],"metadata":{"id":"7ivkskGnbxlD","executionInfo":{"status":"ok","timestamp":1767372432891,"user_tz":360,"elapsed":1,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"7ivkskGnbxlD","execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["7.1 Section Scope\n","\n","Evaluation is strictly section-scoped:\n","\n","- Item 7\n","  - Evaluated label: `MONEY`\n","- Item 10\n","  - Evaluated labels: `PERSON`,`TITLE`, `ORG`\n","\n","Predictions outside the evaluated section or label set are ignored.\n","Offsets are always interpreted relative to the section text."],"metadata":{"id":"tZpqgt5pbypQ"},"id":"tZpqgt5pbypQ"},{"cell_type":"code","source":["# Section 7.1: Section + label routing\n","\n","EVAL_LABELS_BY_SECTION = {\n","    \"item_7\": {\"MONEY\"},\n","    \"item_10\": {\"PERSON\", \"TITLE\", \"ORG\"},\n","}\n","\n","\n","def is_eval_label(section: str, label: str) -> bool:\n","    return label in EVAL_LABELS_BY_SECTION.get(section, set())\n"],"metadata":{"id":"yeBBbR-gb5ab","executionInfo":{"status":"ok","timestamp":1767372432893,"user_tz":360,"elapsed":1,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"yeBBbR-gb5ab","execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["7.2 Gold Assumptions\n","\n","Gold annotations:\n","- are authoritative\n","- are section-scoped\n","- use character offsets\n","- must exactly match the underlying section text slice\n","\n","Gold offsets are validated prior to evaluation."],"metadata":{"id":"Z67LU4o4cLTi"},"id":"Z67LU4o4cLTi"},{"cell_type":"code","source":["# Section 7.2: Gold normalization\n","\n","def gold_spans_from_doc(gold: GoldDoc) -> List[GoldSpan]:\n","    spans: List[GoldSpan] = []\n","\n","    for ann in gold.annotations:\n","        if not is_eval_label(ann.section, ann.label):\n","            continue\n","\n","        spans.append(\n","            GoldSpan(\n","                label=ann.label,\n","                section=ann.section,\n","                start=ann.start,\n","                end=ann.end,\n","            )\n","        )\n","\n","    return spans\n"],"metadata":{"id":"HmeKfh2PcSje","executionInfo":{"status":"ok","timestamp":1767372432894,"user_tz":360,"elapsed":0,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"HmeKfh2PcSje","execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["7.3 Prediction Source\n","\n","Predictions are sourced from the section routing rules defined in the harness:\n","\n","- Item 7:\n","  - Predictions are routed from `doc.spans[\"money_candidates\"]`\n","  - Candidate label `MONEY_CANDIDATE` is normalized to evaluated label `MONEY`\n","\n","- Item 10\n","  - Predictions are routed from `doc.ents`\n","  - Only evaluated labels are retained: `PERSON`, `TITLE`, `ORG`\n","\n","All predictions are then normalized into a common structure:\n","- `label`\n","- `section`\n","- `start`\n","- `end`\n","\n","Candidate entities are never evaluated directly as candidates; they are either routed and normalized (Item 7 MONEY), or ignored."],"metadata":{"id":"ZVAq_4pJcS7q"},"id":"ZVAq_4pJcS7q"},{"cell_type":"code","source":["def predicted_spans_from_doc(doc, section: str) -> List[PredictedSpan]:\n","    \"\"\"\n","    Normalize predictions into PredictedSpan objects for evaluation.\n","\n","    - Item 7: predictions are not sourced from doc.ents (MONEY is handled elsewhere)\n","    - Item 10: predictions are sourced from doc.ents and filtered by SECTION_LABELS\n","    \"\"\"\n","    # Item 7 MONEY is not evaluated from doc.ents in this project\n","    if section == \"item_7\":\n","        return []\n","\n","    allowed = SECTION_LABELS.get(section, set())\n","    spans: List[PredictedSpan] = []\n","\n","    for ent in doc.ents:\n","        if ent.label_ not in allowed:\n","            continue\n","        spans.append(\n","            PredictedSpan(\n","                label=ent.label_,\n","                section=section,\n","                start=ent.start_char,\n","                end=ent.end_char,\n","            )\n","        )\n","\n","    return spans\n"],"metadata":{"id":"NyKr4KFMd184","executionInfo":{"status":"ok","timestamp":1767372432896,"user_tz":360,"elapsed":1,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"NyKr4KFMd184","execution_count":13,"outputs":[]},{"cell_type":"code","source":["def predicted_money_spans_from_candidates(doc, section: str = \"item_7\") -> List[PredictedSpan]:\n","    \"\"\"\n","    Item 7 prediction source (Option 1):\n","    Use doc.spans[\"money_candidates\"] (populated by candidate_siphon) and normalize to MONEY.\n","    \"\"\"\n","    out: List[PredictedSpan] = []\n","    for sp in doc.spans.get(\"money_candidates\", []):\n","        # candidate spans were labeled MONEY_CANDIDATE; evaluation label is MONEY\n","        out.append(\n","            PredictedSpan(\n","                label=\"MONEY\",\n","                section=section,\n","                start=sp.start_char,\n","                end=sp.end_char,\n","            )\n","        )\n","    return out\n"],"metadata":{"id":"qzUUk9R3iRzL","executionInfo":{"status":"ok","timestamp":1767372432938,"user_tz":360,"elapsed":14,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"qzUUk9R3iRzL","execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["7.4 Alignment Modes\n","\n","Two alignment modes are used:\n","- Strict\n","  - label match\n","  - section match\n","  - exact `(start, end)` match\n","- Relaxed\n","  - label match\n","  - section match\n","  - any character overlap\n","\n","Strict alignment measures exact span recovery.\n","\n","Relaxed alignment captures near-misses and boundary drift."],"metadata":{"id":"SDKVWlwmclXh"},"id":"SDKVWlwmclXh"},{"cell_type":"code","source":["# Section 7.4: Alignment logic\n","\n","def spans_overlap(a: SpanBounds, b: SpanBounds) -> bool:\n","    return not (a[1] <= b[0] or b[1] <= a[0])\n","\n","\n","def strict_match(g: GoldSpan, p: PredictedSpan) -> bool:\n","    return (\n","        g.label == p.label and\n","        g.section == p.section and\n","        g.start == p.start and\n","        g.end == p.end\n","    )\n","\n","\n","def relaxed_match(g: GoldSpan, p: PredictedSpan) -> bool:\n","    if g.label != p.label or g.section != p.section:\n","        return False\n","    return spans_overlap((g.start, g.end), (p.start, p.end))\n"],"metadata":{"id":"OYFyyNnccwh9","executionInfo":{"status":"ok","timestamp":1767372432938,"user_tz":360,"elapsed":12,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"OYFyyNnccwh9","execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["7.5 Match Accounting\n","\n","For each pipeline variant:\n","- TP: gold annotation matched by a prediction\n","- FN: gold annotation with no match\n","- FP: prediction with no gold match\n","\n","Each gold annotation may match at most one prediction per alignment pass."],"metadata":{"id":"NZfspqH_cxCx"},"id":"NZfspqH_cxCx"},{"cell_type":"code","source":["# Section 7.5: Match accounting\n","\n","def align_spans(\n","    gold_spans: List[GoldSpan],\n","    pred_spans: List[PredictedSpan],\n","    *,\n","    matcher,\n",") -> AlignmentResult:\n","    matched_preds = set()\n","    tp = []\n","\n","    for g in gold_spans:\n","        match = None\n","        for i, p in enumerate(pred_spans):\n","            if i in matched_preds:\n","                continue\n","            if matcher(g, p):\n","                match = i\n","                break\n","\n","        if match is not None:\n","            matched_preds.add(match)\n","            tp.append((g, pred_spans[match]))\n","\n","    fn = [g for g in gold_spans if g not in [x[0] for x in tp]]\n","    fp = [p for i, p in enumerate(pred_spans) if i not in matched_preds]\n","\n","    return AlignmentResult(tp, fn, fp)\n"],"metadata":{"id":"i_Sq9-lIc5aW","executionInfo":{"status":"ok","timestamp":1767372432939,"user_tz":360,"elapsed":12,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"i_Sq9-lIc5aW","execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["7.6 Metrics\n","\n","Metrics are reported per:\n","- section\n","- label\n","- pipeline variant\n","\n","Reported metrics:\n","- precision\n","- recall\n","- F1\n","\n","Metrics are computed separately for strict and relaxed alignment."],"metadata":{"id":"_VSSytF_c5sH"},"id":"_VSSytF_c5sH"},{"cell_type":"code","source":["# Section 7.6: Metrics\n","\n","def precision(tp: int, fp: int) -> float:\n","    return tp / (tp + fp) if (tp + fp) else 0.0\n","\n","\n","def recall(tp: int, fn: int) -> float:\n","    return tp / (tp + fn) if (tp + fn) else 0.0\n","\n","\n","def f1(p: float, r: float) -> float:\n","    return 2 * p * r / (p + r) if (p + r) else 0.0\n"],"metadata":{"id":"nhS6kBmMdAie","executionInfo":{"status":"ok","timestamp":1767372432939,"user_tz":360,"elapsed":11,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"nhS6kBmMdAie","execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["8. Run Harness (Single + Twin)\n","\n","This section defines the execution harness used to run filings through spaCy pipelines and produce evaluation-ready predictions. The harness is responsible for:\n","\n","- selecting the appropriate section text\n","- extracting predictions from the correct pipeline variant\n","- normalizing predictions into a common span representation\n","- passing predictions into the Section 7 alignment logic\n","\n","No scoring is performed here. This section produces inputs to evaluation, not metrics."],"metadata":{"id":"Q_DzyLo0eKku"},"id":"Q_DzyLo0eKku"},{"cell_type":"code","source":["# Section 8 — Harness: Paths and checks\n","# Explicitly anchor to Google Drive project root (Colab-safe)\n","PROJECT_ROOT = Path(\"/content/drive/MyDrive/Task 3\")\n","DATA_PATH = PROJECT_ROOT / \"primary_data.json\"\n","GOLD_DIR  = PROJECT_ROOT / \"gold_annotations\"\n","\n","assert DATA_PATH.exists(), f\"Missing primary_data.json at {DATA_PATH}\"\n","assert GOLD_DIR.exists(),  f\"Missing gold_annotations at {GOLD_DIR}\"\n","\n"],"metadata":{"id":"1Gxbqhg4e5fv","executionInfo":{"status":"ok","timestamp":1767372432946,"user_tz":360,"elapsed":16,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"1Gxbqhg4e5fv","execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["8.1 Execution Modes\n","\n","Two execution modes are supported:\n","\n","- Single mode: Runs a single pipeline variant (e.g., `sm_aug`) for focused inspection or debugging.\n","\n","- Twin mode: Runs paired pipelines side-by-side (e.g., `sm_base` vs `sm_aug`, `sm_aug` vs `trf_aug`) to support direct comparison.\n","\n","Both modes operate over the same `DocBundle` objects to ensure consistent inputs."],"metadata":{"id":"Ng9pl75ze55d"},"id":"Ng9pl75ze55d"},{"cell_type":"code","source":["# Section 8.1 — Load primary data and gold\n","def load_primary_data(primary_path: str | Path) -> List[CanonicalFiling]:\n","    \"\"\"\n","    Load primary_data.json where the structure is:\n","        {\n","          \"<filename>.json\": { ...raw filing payload... },\n","          ...\n","        }\n","\n","    Returns:\n","        List[CanonicalFiling]\n","    \"\"\"\n","    primary_path = Path(primary_path)\n","    raw = _read_json(primary_path)\n","\n","    if not isinstance(raw, dict):\n","        raise ValueError(f\"Expected top-level dict in primary_data.json, got {type(raw)}\")\n","\n","    filings: List[CanonicalFiling] = []\n","    skipped = 0\n","\n","    for filename_key, rec in raw.items():\n","        if not isinstance(rec, dict):\n","            skipped += 1\n","            continue\n","\n","        # Inject filename from dict key (authoritative)\n","        rec2 = dict(rec)\n","        rec2[\"filename\"] = rec2.get(\"filename\") or str(filename_key)\n","\n","        filings.append(parse_filing_record(rec2))\n","\n","    # Light sanity check: ensure filenames look like filenames\n","    if filings and not any(f.filename.endswith(\".json\") for f in filings[:10]):\n","        print(\"filenames don't look like '*.json' keys. Check primary_data.json structure.\")\n","\n","    if skipped:\n","        print(f\"Skipped {skipped} non-dict records in primary_data.json\")\n","\n","    return filings\n","\n","\n","def load_gold(gold_dir: str | Path) -> Dict[str, GoldDoc]:\n","    \"\"\"\n","    Load gold docs from gold_annotations/*.json.gold.json\n","\n","    Returns:\n","        Dict[str, GoldDoc] mapping original filing filename -> GoldDoc\n","    \"\"\"\n","    return load_gold_from_dir(gold_dir)\n","\n","\n","# (Recommended) one-cell \"do the thing\" usage:\n","filings = load_primary_data(DATA_PATH)\n","gold_map = load_gold(GOLD_DIR)\n","print(\"Loaded filings:\", len(filings))\n","print(\"Loaded gold docs:\", len(gold_map))\n"],"metadata":{"id":"ccLmL-4UfGlO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767372433170,"user_tz":360,"elapsed":224,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"54661a46-d64d-4174-cfbe-667f029ab1cc"},"id":"ccLmL-4UfGlO","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded filings: 191\n","Loaded gold docs: 8\n"]}]},{"cell_type":"code","source":["filings = load_primary_data(DATA_PATH)\n","print(len(filings))\n","print(filings[0].filename)\n","print(len(filings[0].item_7_text), len(filings[0].item_10_text))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGmpOqQYhsAe","executionInfo":{"status":"ok","timestamp":1767372433289,"user_tz":360,"elapsed":118,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"538d36b4-663b-4aff-9c9b-599597b4c28d"},"id":"AGmpOqQYhsAe","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["191\n","1001601_10K_2020_0001493152-21-008913.json\n","29840 6729\n"]}]},{"cell_type":"markdown","source":["8.2 Section Routing\n","\n","Predictions are generated independently per section:\n","\n","- Item 7\n","  - Source text: CanonicalFiling.item_7_text\n","  - Evaluated label: `MONEY`\n","\n","- Item 10\n","  - Source text: CanonicalFiling.item_10_text\n","  - Evaluated labels: `PERSON`, `TITLE`, `ORG`\n","\n","Each section is processed separately to preserve section-scoped offsets and avoid cross-section contamination."],"metadata":{"id":"eGNn8ZkGfGsV"},"id":"eGNn8ZkGfGsV"},{"cell_type":"code","source":["# 8.2 Section Routing — configuration\n","\n","SECTION_LABELS = {\n","    \"item_7\": {\"MONEY\"},\n","    \"item_10\": {\"PERSON\", \"TITLE\", \"ORG\"},\n","}\n","\n","# Use SECTION_LABELS as the authoritative evaluation scope\n","EVAL_LABELS_BY_SECTION = SECTION_LABELS\n","\n","def is_eval_label(section: str, label: str) -> bool:\n","    return label in EVAL_LABELS_BY_SECTION.get(section, set())\n","\n","# Item 7 money is produced as candidate spans, not ents\n","ITEM7_SPAN_KEY = \"money_candidates\"\n","ITEM7_CANDIDATE_LABEL = \"MONEY_CANDIDATE\"\n","\n","def routed_predictions(doc, *, section: str) -> List[Tuple[int, int, str, str]]:\n","    \"\"\"\n","    Select predictions from a spaCy Doc according to section routing rules.\n","\n","    Returns:\n","        List of (start, end, label, text) tuples\n","        Offsets are section-scoped.\n","    \"\"\"\n","    allowed = SECTION_LABELS.get(section, set())\n","    out: List[Tuple[int, int, str, str]] = []\n","\n","    if section == \"item_7\":\n","        # Pull from doc.spans[\"money_candidates\"] and normalize label to MONEY\n","        for sp in doc.spans.get(ITEM7_SPAN_KEY, []):\n","            # only accept the candidate label we expect\n","            if sp.label_ != ITEM7_CANDIDATE_LABEL:\n","                continue\n","\n","            canon_label = \"MONEY\"\n","            if canon_label not in allowed:\n","                continue\n","\n","            out.append((sp.start_char, sp.end_char, canon_label, sp.text))\n","        return out\n","\n","    # Default: Item 10 (and any future section) routes from doc.ents\n","    for ent in doc.ents:\n","        if ent.label_ not in allowed:\n","            continue\n","        out.append((ent.start_char, ent.end_char, ent.label_, ent.text))\n","\n","    return out\n"],"metadata":{"id":"d5zN5tQFfQCi","executionInfo":{"status":"ok","timestamp":1767372433309,"user_tz":360,"elapsed":14,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"d5zN5tQFfQCi","execution_count":21,"outputs":[]},{"cell_type":"code","source":["# pick a filing with gold (safer)\n","gold_filename = next(iter(gold_map.keys()))\n","f_gold = next(f for f in filings if f.filename == gold_filename)\n","\n","doc7 = pipelines[\"sm_aug\"](f_gold.item_7_text)\n","pred7 = routed_predictions(doc7, section=\"item_7\")\n","\n","print(\"Testing gold-backed filename:\", gold_filename)\n","print(\"Item 7 routed labels:\", {p[2] for p in pred7})\n","print(\"Item 7 routed count:\", len(pred7))\n","print(\"Item 7 sample texts:\", [p[3] for p in pred7[:10]])\n","\n","print(\"doc.spans keys:\", list(doc7.spans.keys()))\n","print(\"money_candidates spans:\", len(doc7.spans.get(\"money_candidates\", [])))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5KxX7QL3CyNx","executionInfo":{"status":"ok","timestamp":1767372434000,"user_tz":360,"elapsed":671,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"ec9f6e38-4c8d-42c8-8b89-cb0b50cad81c"},"id":"5KxX7QL3CyNx","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing gold-backed filename: 1017655_10K_2020_0001654954-21-003649.json\n","Item 7 routed labels: {'MONEY'}\n","Item 7 routed count: 38\n","Item 7 sample texts: ['$3,541', '$19,395', '$12,920,789', '$10,548,295', '$15,854', '$3,541', '$19,395', '$120,190', '$27,845', '$148,035']\n","doc.spans keys: ['money_candidates', 'org_candidates']\n","money_candidates spans: 38\n"]}]},{"cell_type":"markdown","source":["8.3 Pipeline Variants\n","\n","Each `DocBundle` may contain predictions from up to four pipeline variants:\n","\n","- `sm_base`\n","- `sm_aug`\n","- `trf_base`\n","- `trf_aug`\n","\n","The harness dynamically detects which variants are available and runs only those present. This allows:\n","\n","- lightweight iteration with `sm`\n","- higher-quality comparison using `trf`\n","- apples-to-apples evaluation between baseline and rule-augmented pipelines"],"metadata":{"id":"uF2As1UwfQHx"},"id":"uF2As1UwfQHx"},{"cell_type":"code","source":["# Section 8.3 — Pipeline variants (available + helpers)\n","\n","PIPELINE_VARIANTS = (\"sm_base\", \"sm_aug\", \"trf_base\", \"trf_aug\")\n","\n","def available_variants(pipelines: dict) -> List[str]:\n","    \"\"\"\n","    Return pipeline variant keys that exist and are callable.\n","    \"\"\"\n","    out = []\n","    for k in PIPELINE_VARIANTS:\n","        nlp = pipelines.get(k)\n","        if nlp is not None and callable(nlp):\n","            out.append(k)\n","    return out\n","\n","def run_variant_on_section(\n","    filing: CanonicalFiling,\n","    *,\n","    pipelines: dict,\n","    variant: str,\n","    section: str,\n","):\n","    \"\"\"\n","    Run a specific pipeline variant on a single section's text and return the Doc.\n","    \"\"\"\n","    nlp = pipelines.get(variant)\n","    if nlp is None:\n","        raise ValueError(f\"Pipeline variant not found: {variant}\")\n","\n","    if section == \"item_7\":\n","      text = filing.item_7_text or \"\"\n","    elif section == \"item_10\":\n","      text = filing.item_10_text or \"\"\n","    else:\n","      raise ValueError(f\"Unknown section: {section!r}\")\n","    return nlp(text)\n","\n","def run_all_variants_on_section(\n","    filing: CanonicalFiling,\n","    *,\n","    pipelines: dict,\n","    section: str,\n",") -> Dict[str, Any]:\n","    \"\"\"\n","    Run all available variants for a given section and return mapping:\n","        variant -> Doc\n","    \"\"\"\n","    docs = {}\n","    for v in available_variants(pipelines):\n","        docs[v] = run_variant_on_section(filing, pipelines=pipelines, variant=v, section=section)\n","    return docs\n","\n","# --- 8.3 sanity check: show what variants are actually available ---\n","avs = available_variants(pipelines)\n","print(\"Available pipeline variants:\", avs)\n","\n","# Pick one filing to inspect\n","f0 = filings[0]\n"],"metadata":{"id":"JWTzZvB5fbsJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767372434023,"user_tz":360,"elapsed":16,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"1bf168e0-56c9-4de9-ae17-76f7a98d21f3"},"id":"JWTzZvB5fbsJ","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Available pipeline variants: ['sm_base', 'sm_aug', 'trf_base', 'trf_aug']\n"]}]},{"cell_type":"code","source":["print(\"pipelines keys:\", sorted(pipelines.keys()))\n","for k in (\"sm_base\", \"sm_aug\", \"trf_base\", \"trf_aug\"):\n","    v = pipelines.get(k)\n","    print(f\"{k:8} ->\", \"LOADED\" if v is not None else \"None\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HEL3G73I9lTM","executionInfo":{"status":"ok","timestamp":1767372434050,"user_tz":360,"elapsed":26,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"e741e56e-48b2-46d8-f8c0-965822b8ffac"},"id":"HEL3G73I9lTM","execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["pipelines keys: ['sm_aug', 'sm_base', 'trf_aug', 'trf_base']\n","sm_base  -> LOADED\n","sm_aug   -> LOADED\n","trf_base -> LOADED\n","trf_aug  -> LOADED\n"]}]},{"cell_type":"code","source":["# Run all variants for each section (no scoring; just existence + routing output)\n","docs_item7 = run_all_variants_on_section(f0, pipelines=pipelines, section=\"item_7\")\n","docs_item10 = run_all_variants_on_section(f0, pipelines=pipelines, section=\"item_10\")\n","\n","print(\"\\nItem 7 routed labels by variant:\")\n","for v, d in docs_item7.items():\n","    preds = routed_predictions(d, section=\"item_7\")\n","    print(f\"  {v:8s} -> labels={sorted({p[2] for p in preds})}  n={len(preds)}\")\n","\n","print(\"\\nItem 10 routed labels by variant:\")\n","for v, d in docs_item10.items():\n","    preds = routed_predictions(d, section=\"item_10\")\n","    print(f\"  {v:8s} -> labels={sorted({p[2] for p in preds})}  n={len(preds)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKAjkq4R3gUG","executionInfo":{"status":"ok","timestamp":1767372512836,"user_tz":360,"elapsed":78758,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"f2fda604-dd5b-4a6a-d02a-dc2539fdcc29"},"id":"HKAjkq4R3gUG","execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Item 7 routed labels by variant:\n","  sm_base  -> labels=[]  n=0\n","  sm_aug   -> labels=['MONEY']  n=93\n","  trf_base -> labels=[]  n=0\n","  trf_aug  -> labels=['MONEY']  n=93\n","\n","Item 10 routed labels by variant:\n","  sm_base  -> labels=['ORG', 'PERSON']  n=78\n","  sm_aug   -> labels=['PERSON', 'TITLE']  n=52\n","  trf_base -> labels=['ORG', 'PERSON']  n=59\n","  trf_aug  -> labels=['PERSON', 'TITLE']  n=51\n"]}]},{"cell_type":"markdown","source":["8.4 Prediction Normalization\n","\n","All predictions are normalized into a shared structure prior to evaluation:\n","- `label`\n","- `section`\n","- `start offset`\n","- `end offset`\n","\n","Predictions are sourced from the section routing rules (`routed_predictions()`), not directly from spaCy internals:\n","\n","- Item 7:\n","  - routed from doc.spans[\"money_candidates\"]\n","  - candidate label `MONEY_CANDIDATE` is normalized to evaluated label `MONEY`\n","- Item 10\n","  - routed from `doc.ents`\n","  - only evaluated labels are retained (`PERSON`, `TITLE`, `ORG`)\n","\n","At this stage:\n","- offsets are preserved (no boundary adjustment)\n","- candidate entities are not evaluated as candidates\n","- exact duplicate spans may be removed using (`section`, `label`, `start`, `end`) as the dedupe key"],"metadata":{"id":"c13fPSwgfbyn"},"id":"c13fPSwgfbyn"},{"cell_type":"markdown","source":["8.5 Harness Outputs\n","\n","For each document (`CanonicalFiling`) and each available pipeline variant (`sm_base`, `sm_aug`, `trf_base`, `trf_aug`), the harness produces evaluation-ready inputs per section.\n","\n","For each section (`item_7`, `item_10`) and variant:\n","- Predictions (normalized)\n","  - A list of `PredictedSpan` objects created by Section 7.3 (`predicted_spans_from_doc(...)`)\n","  - Includes: label, section, start, end\n","  - Offsets remain section-scoped and unchanged\n","  - Exact duplicates may be removed\n","- Gold spans (when available):\n","  - A list of `GoldSpan` objects created by `gold_spans_from_doc(...)`\n","  - Includes: `label`, `section`, `start`, `end`\n","  - Only spans in evaluation scope are included (per `EVAL_LABELS_BY_SECTION`)\n","\n","For each (section, variant), the harness provides the pair:\n","- `(gold_spans, predicted_spans)`\n","\n","These are passed directly to `align_spans(...)` using:\n","- Strict matching (`strict_match`)\n","- Relaxed matching (`relaxed_match`)\n","\n","The harness output is organized as `document → variant → section → {gold_spans, predicted_spans}`"],"metadata":{"id":"uwifmiO_fjk9"},"id":"uwifmiO_fjk9"},{"cell_type":"markdown","source":["9. Outputs (Human + Machine)\n","\n","This section defines the outputs produced after extraction, routing, and normalization are complete.\n","\n","Outputs are divided into:\n","- Machine outputs (Section 9.1): structured, evaluation-ready data\n","- Human outputs (Section 9.2): readable summaries for inspection"],"metadata":{"id":"EmSMObLANK93"},"id":"EmSMObLANK93"},{"cell_type":"code","source":["# Section 9 setup — gold-only evaluation scope\n","filings = load_primary_data(DATA_PATH)\n","gold_map = load_gold(GOLD_DIR)\n","\n","eval_filings = [f for f in filings if f.filename in gold_map]\n","\n","print(f\"Total filings loaded: {len(filings)}\")\n","print(f\"Filings with gold:     {len(eval_filings)}\")\n","\n","bundles = build_doc_bundles(\n","    filings=eval_filings,\n","    gold_map=gold_map,\n","    pipelines=pipelines,\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vx9g9ZqaQiJa","executionInfo":{"status":"ok","timestamp":1767373269003,"user_tz":360,"elapsed":756170,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"40c202d5-8b3a-4efa-f77a-2fa53fb9514b"},"id":"vx9g9ZqaQiJa","execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Total filings loaded: 191\n","Filings with gold:     8\n"]}]},{"cell_type":"markdown","source":["9.1 Machine Outputs\n","\n","Machine outputs are structured, deterministic, and suitable for downstream scoring and aggregation.\n","\n","Outputs are organized as:\n","\n","`document → pipeline variant → section → outputs`\n","\n","Where:\n","- document is identified by filing filename\n","- pipeline variant is one of: `sm_base`, `sm_aug`, `trf_base`, `trf_aug` (when available)\n","- section is one of: `item_7`, `item_10`\n","\n","For each (`document`, `variant`, `section`) combination, machine outputs include:\n","- Normalized prediction spans\n","  - Produced by Section 7.3\n","  - Fields: `label`, `section`, `start`, `end`\n","  - Offsets are section-scoped and unchanged\n","  - Exact duplicate spans may be removed\n","- Gold spans (when available)\n","  - Produced by Section 7.2\n","  - Fields: `label`, `section`, `start`, `end`\n","  - Limited to labels within evaluation scope"],"metadata":{"id":"EZbVd90oO3hG"},"id":"EZbVd90oO3hG"},{"cell_type":"code","source":["# Section 9.1 — Machine Outputs\n","def build_machine_outputs(\n","    bundles: List[DocBundle],\n","    *,\n","    pipelines: dict,\n",") -> Dict[str, Any]:\n","    results: Dict[str, Any] = {}\n","    variants = available_variants(pipelines)\n","\n","    for bundle in bundles:\n","        filing = bundle.filing\n","        filename = filing.filename\n","\n","        results[filename] = {\n","            \"meta\": {\n","                \"company\": filing.company,\n","                \"filing_date\": filing.filing_date,\n","                \"period_of_report\": filing.period_of_report,\n","            },\n","            \"variants\": {},\n","        }\n","\n","        for variant in variants:\n","            results[filename][\"variants\"][variant] = {}\n","\n","            for section in SECTION_LABELS.keys():\n","                # bundle attrs are item7_* / item10_* (no underscore)\n","                attr = f\"{section.replace('_', '')}_{variant}\"\n","                doc = getattr(bundle, attr, None)\n","                if doc is None:\n","                    continue\n","\n","                if section == \"item_7\":\n","                  preds = predicted_money_spans_from_candidates(doc, section=\"item_7\")\n","                else:\n","                  preds = predicted_spans_from_doc(doc, section) or []\n","\n","                gold = []\n","                if bundle.gold:\n","                    gold = [g for g in gold_spans_from_doc(bundle.gold) if g.section == section]\n","\n","                results[filename][\"variants\"][variant][section] = {\n","                    \"pred\": preds,\n","                    \"gold\": gold,\n","                }\n","\n","    return results\n"],"metadata":{"id":"cG22RXEWP2Lm","executionInfo":{"status":"ok","timestamp":1767373269005,"user_tz":360,"elapsed":1,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"cG22RXEWP2Lm","execution_count":27,"outputs":[]},{"cell_type":"code","source":["machine_outputs = build_machine_outputs(bundles, pipelines=pipelines)\n","\n","some_file = next(iter(machine_outputs))\n","print(machine_outputs[some_file].keys())\n","print(machine_outputs[some_file][\"variants\"].keys())\n","print(machine_outputs[some_file][\"variants\"][\"sm_aug\"].keys())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jdGn7WwqQVqx","executionInfo":{"status":"ok","timestamp":1767373269043,"user_tz":360,"elapsed":4,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"8bd72fcc-b9b4-44bf-b0b3-8ab6e7e2324e"},"id":"jdGn7WwqQVqx","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['meta', 'variants'])\n","dict_keys(['sm_base', 'sm_aug', 'trf_base', 'trf_aug'])\n","dict_keys(['item_7', 'item_10'])\n"]}]},{"cell_type":"code","source":["# --- Section 9 sanity checks (quick) ---\n","\n","# Pick one document\n","filename = next(iter(machine_outputs))\n","doc_out = machine_outputs[filename]\n","\n","print(\"FILE:\", filename)\n","print(\"META:\", doc_out[\"meta\"].keys())\n","print(\"VARIANTS:\", list(doc_out[\"variants\"].keys()))\n","\n","# Pick one variant\n","variant = next(iter(doc_out[\"variants\"]))\n","print(\"\\nVARIANT:\", variant)\n","\n","for section in (\"item_7\", \"item_10\"):\n","    sec = doc_out[\"variants\"][variant].get(section)\n","    if not sec:\n","        print(f\"  {section}: <missing>\")\n","        continue\n","\n","    preds = sec[\"pred\"] or []\n","    gold = sec[\"gold\"] or []\n","\n","    print(f\"\\n  {section}:\")\n","    print(f\"    pred spans: {len(preds)}\")\n","    print(f\"    gold spans: {len(gold) if gold is not None else 'None'}\")\n","\n","    # Peek at first span if present\n","    if preds:\n","        p = preds[0]\n","        print(f\"    sample pred: ({p.label}, {p.start}:{p.end})\")\n","\n","    if gold:\n","        g = gold[0]\n","        print(f\"    sample gold: ({g.label}, {g.start}:{g.end})\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3N6ajNfUa5Bb","executionInfo":{"status":"ok","timestamp":1767373269099,"user_tz":360,"elapsed":55,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"b8301d28-6925-416e-ac75-1ba26e00ec85"},"id":"3N6ajNfUa5Bb","execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["FILE: 1017655_10K_2020_0001654954-21-003649.json\n","META: dict_keys(['company', 'filing_date', 'period_of_report'])\n","VARIANTS: ['sm_base', 'sm_aug', 'trf_base', 'trf_aug']\n","\n","VARIANT: sm_base\n","\n","  item_7:\n","    pred spans: 0\n","    gold spans: 63\n","    sample gold: (MONEY, 13031:13037)\n","\n","  item_10:\n","    pred spans: 95\n","    gold spans: 62\n","    sample pred: (PERSON, 222:237)\n","    sample gold: (PERSON, 222:241)\n"]}]},{"cell_type":"markdown","source":["9.2 Human Outputs\n","\n","Human outputs provide readable views of the machine outputs for inspection, debugging, and comparison. These outputs are derived directly from the machine outputs defined in Section 9.1 and do not introduce new logic.\n","\n","Human outputs may include:\n","- per-document summaries grouped by label\n","- per-section views (item_7, item_10)\n","- side-by-side comparisons across pipeline variants\n","- counts of predicted, gold, and matched spans\n","\n","Human outputs are intended for analysis and presentation only and are not used for scoring or aggregation."],"metadata":{"id":"ekdtjFi_Psuz"},"id":"ekdtjFi_Psuz"},{"cell_type":"code","source":["def print_human_summary(machine_outputs, filename):\n","    doc = machine_outputs[filename]\n","    print(f\"\\nFILE: {filename}\")\n","    print(f\"Company: {doc['meta'].get('company','')}\")\n","    print(\"-\" * 60)\n","\n","    for variant, vdata in doc[\"variants\"].items():\n","        print(f\"\\nVARIANT: {variant}\")\n","        for section, sdata in vdata.items():\n","            preds = sdata[\"pred\"] or []\n","            gold = sdata[\"gold\"] or []\n","\n","            print(f\"  {section}:\")\n","            print(f\"    pred spans: {len(preds)}\")\n","            print(f\"    gold spans: {len(gold)}\")\n","\n","            if preds:\n","                p = preds[0]\n","                print(f\"    sample pred: {p.label} ({p.start}:{p.end})\")\n","\n","            if gold:\n","                g = gold[0]\n","                print(f\"    sample gold: {g.label} ({g.start}:{g.end})\")\n"],"metadata":{"id":"N34OYJZbbjRo","executionInfo":{"status":"ok","timestamp":1767373269100,"user_tz":360,"elapsed":7,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}}},"id":"N34OYJZbbjRo","execution_count":30,"outputs":[]},{"cell_type":"code","source":["fname = next(iter(machine_outputs))\n","print_human_summary(machine_outputs, fname)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"plDXAR_Abo-8","executionInfo":{"status":"ok","timestamp":1767373269100,"user_tz":360,"elapsed":5,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"e3cf1e47-c160-474b-b93c-e244706dc7b4"},"id":"plDXAR_Abo-8","execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","FILE: 1017655_10K_2020_0001654954-21-003649.json\n","Company: PAID INC\n","------------------------------------------------------------\n","\n","VARIANT: sm_base\n","  item_7:\n","    pred spans: 0\n","    gold spans: 63\n","    sample gold: MONEY (13031:13037)\n","  item_10:\n","    pred spans: 95\n","    gold spans: 62\n","    sample pred: PERSON (222:237)\n","    sample gold: PERSON (222:241)\n","\n","VARIANT: sm_aug\n","  item_7:\n","    pred spans: 38\n","    gold spans: 63\n","    sample pred: MONEY (13031:13037)\n","    sample gold: MONEY (13031:13037)\n","  item_10:\n","    pred spans: 51\n","    gold spans: 62\n","    sample pred: PERSON (222:237)\n","    sample gold: PERSON (222:241)\n","\n","VARIANT: trf_base\n","  item_7:\n","    pred spans: 0\n","    gold spans: 63\n","    sample gold: MONEY (13031:13037)\n","  item_10:\n","    pred spans: 79\n","    gold spans: 62\n","    sample pred: PERSON (259:270)\n","    sample gold: PERSON (222:241)\n","\n","VARIANT: trf_aug\n","  item_7:\n","    pred spans: 38\n","    gold spans: 63\n","    sample pred: MONEY (13031:13037)\n","    sample gold: MONEY (13031:13037)\n","  item_10:\n","    pred spans: 48\n","    gold spans: 62\n","    sample pred: TITLE (250:253)\n","    sample gold: PERSON (222:241)\n"]}]},{"cell_type":"markdown","source":["## 10. Scoring\n","\n","This section scores each pipeline variant against gold annotations using the\n","machine outputs produced in Section 9.\n","\n","Scoring is performed post-extraction and does not modify predictions or gold\n","annotations.\n","\n","### Evaluation Scope\n","\n","- **Item 7**: MONEY  \n","  - Predictions sourced from `money_candidates` in augmented pipelines\n","- **Item 10**: PERSON, TITLE, ORG  \n","  - Predictions sourced from `doc.ents`\n","\n","Pipeline variants without applicable predictions for a section are scored\n","normally.\n","\n","### Alignment\n","\n","Two alignment modes are used:\n","\n","- **Strict**: exact `(start, end)` match\n","- **Relaxed**: any character overlap\n","\n","Alignment requires matching label and section. Each gold span may match at most\n","one prediction per pass.\n","\n","### Metrics\n","\n","Metrics are computed per pipeline variant and section:\n","- precision\n","- recall\n","- F1 score\n","\n","Strict and relaxed metrics are reported separately.\n","\n","### Notes\n","\n","- Offsets are authoritative\n","- No post-hoc adjustment or gold-informed filtering is applied\n"],"metadata":{"id":"dA4gwBSRmToJ"},"id":"dA4gwBSRmToJ"},{"cell_type":"code","source":["# Section 10: Scoring (Micro)\n","ALIGN_MODES = {\n","    \"strict\": strict_match,\n","    \"relaxed\": relaxed_match,\n","}\n","\n","def score_one_pass(\n","    gold_spans: List[GoldSpan],\n","    pred_spans: List[PredictedSpan],\n","    *,\n","    mode: str,\n",") -> Dict[str, Any]:\n","    \"\"\"\n","    Score one (gold, pred) list using a single alignment mode.\n","    Returns counts + metrics.\n","    \"\"\"\n","    matcher = ALIGN_MODES[mode]\n","    res = align_spans(gold_spans, pred_spans, matcher=matcher)\n","\n","    tp = len(res.true_positives)\n","    fn = len(res.false_negatives)\n","    fp = len(res.false_positives)\n","\n","    p = precision(tp, fp)\n","    r = recall(tp, fn)\n","    return {\n","        \"mode\": mode,\n","        \"tp\": tp,\n","        \"fp\": fp,\n","        \"fn\": fn,\n","        \"precision\": p,\n","        \"recall\": r,\n","        \"f1\": f1(p, r),\n","    }\n","\n","\n","def score_machine_outputs(machine_outputs: Dict[str, Any]) -> pd.DataFrame:\n","    \"\"\"\n","    Flatten per-doc scores into a dataframe:\n","      filename, variant, section, mode, tp, fp, fn, precision, recall, f1\n","    \"\"\"\n","    rows = []\n","\n","    for filename, docdata in machine_outputs.items():\n","        variants = docdata.get(\"variants\", {})\n","        for variant, vdata in variants.items():\n","            for section, sdata in vdata.items():\n","                gold_spans = sdata.get(\"gold\", []) or []\n","                pred_spans = sdata.get(\"pred\", []) or []\n","\n","                # Score both strict + relaxed\n","                for mode in (\"strict\", \"relaxed\"):\n","                    out = score_one_pass(gold_spans, pred_spans, mode=mode)\n","                    rows.append({\n","                        \"filename\": filename,\n","                        \"variant\": variant,\n","                        \"section\": section,\n","                        **out,\n","                    })\n","\n","    return pd.DataFrame(rows)\n","\n","\n","def micro_aggregate(scores_df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Micro-average by summing TP/FP/FN, then recomputing metrics.\n","    Grouped by: variant, section, mode\n","    \"\"\"\n","    grouped = (\n","        scores_df\n","        .groupby([\"variant\", \"section\", \"mode\"], as_index=False)[[\"tp\", \"fp\", \"fn\"]]\n","        .sum()\n","    )\n","\n","    # Recompute metrics from summed counts (micro)\n","    grouped[\"precision\"] = grouped.apply(lambda r: precision(int(r.tp), int(r.fp)), axis=1)\n","    grouped[\"recall\"]    = grouped.apply(lambda r: recall(int(r.tp), int(r.fn)), axis=1)\n","    grouped[\"f1\"]        = grouped.apply(lambda r: f1(float(r.precision), float(r.recall)), axis=1)\n","\n","    # Nice ordering\n","    return grouped.sort_values([\"section\", \"mode\", \"variant\"]).reset_index(drop=True)\n","\n","\n","# ---- Run scoring ----\n","scores_df = score_machine_outputs(machine_outputs)\n","micro_df  = micro_aggregate(scores_df)\n","\n","print(\"Per-doc score rows:\", len(scores_df))\n","print(\"Micro-aggregated rows:\", len(micro_df))\n","\n","micro_df\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":586},"id":"9-JSrmwNcVDD","executionInfo":{"status":"ok","timestamp":1767373269428,"user_tz":360,"elapsed":300,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"2872114d-d3b7-4e44-83f2-61d1389acf59"},"id":"9-JSrmwNcVDD","execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Per-doc score rows: 128\n","Micro-aggregated rows: 16\n"]},{"output_type":"execute_result","data":{"text/plain":["     variant  section     mode   tp   fp   fn  precision    recall        f1\n","0     sm_aug  item_10  relaxed  140  183  139   0.433437  0.501792  0.465116\n","1    sm_base  item_10  relaxed  110  408  169   0.212355  0.394265  0.276035\n","2    trf_aug  item_10  relaxed  139  156  140   0.471186  0.498208  0.484321\n","3   trf_base  item_10  relaxed  130  287  149   0.311751  0.465950  0.373563\n","4     sm_aug  item_10   strict  111  212  168   0.343653  0.397849  0.368771\n","5    sm_base  item_10   strict   87  431  192   0.167954  0.311828  0.218319\n","6    trf_aug  item_10   strict  112  183  167   0.379661  0.401434  0.390244\n","7   trf_base  item_10   strict  116  301  163   0.278177  0.415771  0.333333\n","8     sm_aug   item_7  relaxed  522    9  420   0.983051  0.554140  0.708758\n","9    sm_base   item_7  relaxed    0    0  942   0.000000  0.000000  0.000000\n","10   trf_aug   item_7  relaxed  522    9  420   0.983051  0.554140  0.708758\n","11  trf_base   item_7  relaxed    0    0  942   0.000000  0.000000  0.000000\n","12    sm_aug   item_7   strict  298  233  644   0.561205  0.316348  0.404616\n","13   sm_base   item_7   strict    0    0  942   0.000000  0.000000  0.000000\n","14   trf_aug   item_7   strict  298  233  644   0.561205  0.316348  0.404616\n","15  trf_base   item_7   strict    0    0  942   0.000000  0.000000  0.000000"],"text/html":["\n","  <div id=\"df-17c3ebd4-5107-4db6-982a-645cb800f510\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>variant</th>\n","      <th>section</th>\n","      <th>mode</th>\n","      <th>tp</th>\n","      <th>fp</th>\n","      <th>fn</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sm_aug</td>\n","      <td>item_10</td>\n","      <td>relaxed</td>\n","      <td>140</td>\n","      <td>183</td>\n","      <td>139</td>\n","      <td>0.433437</td>\n","      <td>0.501792</td>\n","      <td>0.465116</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sm_base</td>\n","      <td>item_10</td>\n","      <td>relaxed</td>\n","      <td>110</td>\n","      <td>408</td>\n","      <td>169</td>\n","      <td>0.212355</td>\n","      <td>0.394265</td>\n","      <td>0.276035</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>trf_aug</td>\n","      <td>item_10</td>\n","      <td>relaxed</td>\n","      <td>139</td>\n","      <td>156</td>\n","      <td>140</td>\n","      <td>0.471186</td>\n","      <td>0.498208</td>\n","      <td>0.484321</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>trf_base</td>\n","      <td>item_10</td>\n","      <td>relaxed</td>\n","      <td>130</td>\n","      <td>287</td>\n","      <td>149</td>\n","      <td>0.311751</td>\n","      <td>0.465950</td>\n","      <td>0.373563</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sm_aug</td>\n","      <td>item_10</td>\n","      <td>strict</td>\n","      <td>111</td>\n","      <td>212</td>\n","      <td>168</td>\n","      <td>0.343653</td>\n","      <td>0.397849</td>\n","      <td>0.368771</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>sm_base</td>\n","      <td>item_10</td>\n","      <td>strict</td>\n","      <td>87</td>\n","      <td>431</td>\n","      <td>192</td>\n","      <td>0.167954</td>\n","      <td>0.311828</td>\n","      <td>0.218319</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>trf_aug</td>\n","      <td>item_10</td>\n","      <td>strict</td>\n","      <td>112</td>\n","      <td>183</td>\n","      <td>167</td>\n","      <td>0.379661</td>\n","      <td>0.401434</td>\n","      <td>0.390244</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>trf_base</td>\n","      <td>item_10</td>\n","      <td>strict</td>\n","      <td>116</td>\n","      <td>301</td>\n","      <td>163</td>\n","      <td>0.278177</td>\n","      <td>0.415771</td>\n","      <td>0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>sm_aug</td>\n","      <td>item_7</td>\n","      <td>relaxed</td>\n","      <td>522</td>\n","      <td>9</td>\n","      <td>420</td>\n","      <td>0.983051</td>\n","      <td>0.554140</td>\n","      <td>0.708758</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>sm_base</td>\n","      <td>item_7</td>\n","      <td>relaxed</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>942</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>trf_aug</td>\n","      <td>item_7</td>\n","      <td>relaxed</td>\n","      <td>522</td>\n","      <td>9</td>\n","      <td>420</td>\n","      <td>0.983051</td>\n","      <td>0.554140</td>\n","      <td>0.708758</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>trf_base</td>\n","      <td>item_7</td>\n","      <td>relaxed</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>942</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>sm_aug</td>\n","      <td>item_7</td>\n","      <td>strict</td>\n","      <td>298</td>\n","      <td>233</td>\n","      <td>644</td>\n","      <td>0.561205</td>\n","      <td>0.316348</td>\n","      <td>0.404616</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>sm_base</td>\n","      <td>item_7</td>\n","      <td>strict</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>942</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>trf_aug</td>\n","      <td>item_7</td>\n","      <td>strict</td>\n","      <td>298</td>\n","      <td>233</td>\n","      <td>644</td>\n","      <td>0.561205</td>\n","      <td>0.316348</td>\n","      <td>0.404616</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>trf_base</td>\n","      <td>item_7</td>\n","      <td>strict</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>942</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17c3ebd4-5107-4db6-982a-645cb800f510')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-17c3ebd4-5107-4db6-982a-645cb800f510 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-17c3ebd4-5107-4db6-982a-645cb800f510');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-1aa5e1cd-ec1c-48d2-99e6-ec79d532343f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1aa5e1cd-ec1c-48d2-99e6-ec79d532343f')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-1aa5e1cd-ec1c-48d2-99e6-ec79d532343f button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_d9dceceb-dc8b-48e2-adca-a81783cd3803\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('micro_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_d9dceceb-dc8b-48e2-adca-a81783cd3803 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('micro_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"micro_df","summary":"{\n  \"name\": \"micro_df\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"variant\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"sm_base\",\n          \"trf_base\",\n          \"sm_aug\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"section\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"item_7\",\n          \"item_10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"strict\",\n          \"relaxed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 167,\n        \"min\": 0,\n        \"max\": 522,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          87,\n          140\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 148,\n        \"min\": 0,\n        \"max\": 431,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0,\n          408\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 338,\n        \"min\": 139,\n        \"max\": 942,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          192,\n          139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3121461988106746,\n        \"min\": 0.0,\n        \"max\": 0.9830508474576272,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.16795366795366795,\n          0.43343653250773995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20539712288026651,\n        \"min\": 0.0,\n        \"max\": 0.554140127388535,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.3118279569892473,\n          0.5017921146953405\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2304863749713043,\n        \"min\": 0.0,\n        \"max\": 0.7087576374745418,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.21831869510664992,\n          0.46511627906976744\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["micro_df.sort_values([\"section\", \"mode\", \"f1\"], ascending=[True, True, False]).head(12)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"l5MSH4sjoLaX","executionInfo":{"status":"ok","timestamp":1767373269440,"user_tz":360,"elapsed":11,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"515363db-dcb3-497d-82a9-92774c849702"},"id":"l5MSH4sjoLaX","execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     variant  section     mode   tp   fp   fn  precision    recall        f1\n","2    trf_aug  item_10  relaxed  139  156  140   0.471186  0.498208  0.484321\n","0     sm_aug  item_10  relaxed  140  183  139   0.433437  0.501792  0.465116\n","3   trf_base  item_10  relaxed  130  287  149   0.311751  0.465950  0.373563\n","1    sm_base  item_10  relaxed  110  408  169   0.212355  0.394265  0.276035\n","6    trf_aug  item_10   strict  112  183  167   0.379661  0.401434  0.390244\n","4     sm_aug  item_10   strict  111  212  168   0.343653  0.397849  0.368771\n","7   trf_base  item_10   strict  116  301  163   0.278177  0.415771  0.333333\n","5    sm_base  item_10   strict   87  431  192   0.167954  0.311828  0.218319\n","8     sm_aug   item_7  relaxed  522    9  420   0.983051  0.554140  0.708758\n","10   trf_aug   item_7  relaxed  522    9  420   0.983051  0.554140  0.708758\n","9    sm_base   item_7  relaxed    0    0  942   0.000000  0.000000  0.000000\n","11  trf_base   item_7  relaxed    0    0  942   0.000000  0.000000  0.000000"],"text/html":["\n","  <div id=\"df-0db6e9e6-6d54-41e5-a4e0-b4134c89c3ed\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>variant</th>\n","      <th>section</th>\n","      <th>mode</th>\n","      <th>tp</th>\n","      <th>fp</th>\n","      <th>fn</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>trf_aug</td>\n","      <td>item_10</td>\n","      <td>relaxed</td>\n","      <td>139</td>\n","      <td>156</td>\n","      <td>140</td>\n","      <td>0.471186</td>\n","      <td>0.498208</td>\n","      <td>0.484321</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>sm_aug</td>\n","      <td>item_10</td>\n","      <td>relaxed</td>\n","      <td>140</td>\n","      <td>183</td>\n","      <td>139</td>\n","      <td>0.433437</td>\n","      <td>0.501792</td>\n","      <td>0.465116</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>trf_base</td>\n","      <td>item_10</td>\n","      <td>relaxed</td>\n","      <td>130</td>\n","      <td>287</td>\n","      <td>149</td>\n","      <td>0.311751</td>\n","      <td>0.465950</td>\n","      <td>0.373563</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sm_base</td>\n","      <td>item_10</td>\n","      <td>relaxed</td>\n","      <td>110</td>\n","      <td>408</td>\n","      <td>169</td>\n","      <td>0.212355</td>\n","      <td>0.394265</td>\n","      <td>0.276035</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>trf_aug</td>\n","      <td>item_10</td>\n","      <td>strict</td>\n","      <td>112</td>\n","      <td>183</td>\n","      <td>167</td>\n","      <td>0.379661</td>\n","      <td>0.401434</td>\n","      <td>0.390244</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sm_aug</td>\n","      <td>item_10</td>\n","      <td>strict</td>\n","      <td>111</td>\n","      <td>212</td>\n","      <td>168</td>\n","      <td>0.343653</td>\n","      <td>0.397849</td>\n","      <td>0.368771</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>trf_base</td>\n","      <td>item_10</td>\n","      <td>strict</td>\n","      <td>116</td>\n","      <td>301</td>\n","      <td>163</td>\n","      <td>0.278177</td>\n","      <td>0.415771</td>\n","      <td>0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>sm_base</td>\n","      <td>item_10</td>\n","      <td>strict</td>\n","      <td>87</td>\n","      <td>431</td>\n","      <td>192</td>\n","      <td>0.167954</td>\n","      <td>0.311828</td>\n","      <td>0.218319</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>sm_aug</td>\n","      <td>item_7</td>\n","      <td>relaxed</td>\n","      <td>522</td>\n","      <td>9</td>\n","      <td>420</td>\n","      <td>0.983051</td>\n","      <td>0.554140</td>\n","      <td>0.708758</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>trf_aug</td>\n","      <td>item_7</td>\n","      <td>relaxed</td>\n","      <td>522</td>\n","      <td>9</td>\n","      <td>420</td>\n","      <td>0.983051</td>\n","      <td>0.554140</td>\n","      <td>0.708758</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>sm_base</td>\n","      <td>item_7</td>\n","      <td>relaxed</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>942</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>trf_base</td>\n","      <td>item_7</td>\n","      <td>relaxed</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>942</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0db6e9e6-6d54-41e5-a4e0-b4134c89c3ed')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0db6e9e6-6d54-41e5-a4e0-b4134c89c3ed button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0db6e9e6-6d54-41e5-a4e0-b4134c89c3ed');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-a20acfdf-7617-487b-abee-53ec8801bc80\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a20acfdf-7617-487b-abee-53ec8801bc80')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-a20acfdf-7617-487b-abee-53ec8801bc80 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"micro_df\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"variant\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"sm_aug\",\n          \"sm_base\",\n          \"trf_aug\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"section\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"item_7\",\n          \"item_10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"strict\",\n          \"relaxed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 172,\n        \"min\": 0,\n        \"max\": 522,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          522,\n          140\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 155,\n        \"min\": 0,\n        \"max\": 431,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          9,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 300,\n        \"min\": 139,\n        \"max\": 942,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          420,\n          139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31862274489137893,\n        \"min\": 0.0,\n        \"max\": 0.9830508474576272,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9830508474576272,\n          0.43343653250773995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18882503193528988,\n        \"min\": 0.0,\n        \"max\": 0.554140127388535,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.554140127388535,\n          0.5017921146953405\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.225222083351542,\n        \"min\": 0.0,\n        \"max\": 0.7087576374745418,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7087576374745418,\n          0.46511627906976744\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# -------------------------------\n","# ONE-TIME UNDER-THE-HOOD INSPECTION\n","# -------------------------------\n","\n","# pick a gold-backed file (first one is fine)\n","filename = next(iter(gold_map.keys()))\n","filing = next(f for f in filings if f.filename == filename)\n","gold = gold_map[filename]\n","\n","variant = \"trf_aug\"     # try: sm_base, sm_aug, trf_base, trf_aug\n","section = \"item_10\"     # or \"item_7\"\n","\n","print(f\"\\nFILE: {filename}\")\n","print(f\"Company: {filing.company}\")\n","print(f\"Variant: {variant} | Section: {section}\")\n","print(\"-\" * 70)\n","\n","# run pipeline directly (no harness magic)\n","nlp = pipelines[variant]\n","text = filing.item_10_text if section == \"item_10\" else filing.item_7_text\n","doc = nlp(text)\n","\n","print(\"\\nRAW spaCy ENTS (first 20):\")\n","for e in doc.ents[:20]:\n","    print(f\"  {e.label_:8s} {e.start_char:5d}:{e.end_char:5d}  → {e.text!r}\")\n","\n","# routed predictions (what you actually score)\n","preds = routed_predictions(doc, section=section)\n","\n","print(f\"\\nROUTED PREDICTIONS (first 20)  n={len(preds)}:\")\n","for s, e, lbl, txt in preds[:20]:\n","    print(f\"  {lbl:8s} {s:5d}:{e:5d}  → {txt!r}\")\n","\n","# gold spans for this section\n","gold_spans = [\n","    a for a in gold.annotations\n","    if a.section == section\n","]\n","\n","print(f\"\\nGOLD SPANS (first 20)  n={len(gold_spans)}:\")\n","for a in gold_spans[:20]:\n","    print(f\"  {a.label:8s} {a.start:5d}:{a.end:5d}  → {a.text!r}\")\n","\n","# text window helper (inline, no function)\n","def show_window(start, end, pad=60):\n","    s0 = max(0, start - pad)\n","    e0 = min(len(text), end + pad)\n","    return text[s0:start] + \"[[\" + text[start:end] + \"]]\" + text[end:e0]\n","\n","# show a few side-by-side examples\n","print(\"\\nSIDE-BY-SIDE EXAMPLES\")\n","print(\"-\" * 30)\n","\n","for i in range(min(5, len(preds))):\n","    s, e, lbl, txt = preds[i]\n","    print(f\"\\nPRED {lbl} {s}:{e}\")\n","    print(show_window(s, e))\n","\n","for i in range(min(5, len(gold_spans))):\n","    a = gold_spans[i]\n","    print(f\"\\nGOLD {a.label} {a.start}:{a.end}\")\n","    print(show_window(a.start, a.end))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8Tm3H_Sq6MP","executionInfo":{"status":"ok","timestamp":1767373542653,"user_tz":360,"elapsed":9079,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"f426ef58-7237-494b-81e4-3ba4010a7cdd"},"id":"R8Tm3H_Sq6MP","execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","FILE: 1017655_10K_2020_0001654954-21-003649.json\n","Company: PAID INC\n","Variant: trf_aug | Section: item_10\n","----------------------------------------------------------------------\n","\n","RAW spaCy ENTS (first 20):\n","  CARDINAL     5:    7  → '10'\n","  TITLE      250:  253  → 'CEO'\n","  TITLE      255:  258  → 'CFO'\n","  PERSON     259:  270  → 'David Scott'\n","  TITLE      271:  274  → 'COO'\n","  PERSON     275:  288  → 'Andrew Pilaro'\n","  TITLE      289:  297  → 'Director'\n","  PERSON     298:  312  → 'Laurie Bradley'\n","  TITLE      313:  321  → 'Director'\n","  PERSON     322:  333  → 'David Ogden'\n","  TITLE      334:  342  → 'Director'\n","  PERSON     343:  356  → 'Andrew Pilaro'\n","  DATE       375:  394  → 'September 19, 2000,'\n","  EVENT      418:  457  → 'the 2001 Annual Meeting of Stockholders'\n","  DATE       515:  529  → 'March 27, 2021'\n","  CARDINAL   609:  613  → 'five'\n","  CARDINAL   627:  632  → 'three'\n","  PERSON     658:  673  → 'W. Austin Lewis'\n","  PERSON     682:  693  → 'Allan Pratt'\n","  GPE        754:  762  → 'Delaware'\n","\n","ROUTED PREDICTIONS (first 20)  n=48:\n","  TITLE      250:  253  → 'CEO'\n","  TITLE      255:  258  → 'CFO'\n","  PERSON     259:  270  → 'David Scott'\n","  TITLE      271:  274  → 'COO'\n","  PERSON     275:  288  → 'Andrew Pilaro'\n","  TITLE      289:  297  → 'Director'\n","  PERSON     298:  312  → 'Laurie Bradley'\n","  TITLE      313:  321  → 'Director'\n","  PERSON     322:  333  → 'David Ogden'\n","  TITLE      334:  342  → 'Director'\n","  PERSON     343:  356  → 'Andrew Pilaro'\n","  PERSON     658:  673  → 'W. Austin Lewis'\n","  PERSON     682:  693  → 'Allan Pratt'\n","  PERSON    1571: 1584  → 'Andrew Pilaro'\n","  TITLE     1601: 1609  → 'Director'\n","  TITLE     1646: 1655  → 'President'\n","  PERSON    1798: 1804  → 'Pilaro'\n","  TITLE     1829: 1837  → 'director'\n","  PERSON    1922: 1937  → 'W. Austin Lewis'\n","  TITLE     1962: 1965  → 'CFO'\n","\n","GOLD SPANS (first 20)  n=62:\n","  PERSON     222:  241  → 'W. Austin Lewis, IV'\n","  PERSON     259:  270  → 'David Scott'\n","  PERSON     275:  288  → 'Andrew Pilaro'\n","  PERSON     298:  312  → 'Laurie Bradley'\n","  PERSON     322:  333  → 'David Ogden'\n","  PERSON     343:  356  → 'Andrew Pilaro'\n","  PERSON     658:  677  → 'W. Austin Lewis, IV'\n","  PERSON     682:  693  → 'Allan Pratt'\n","  PERSON    1571: 1584  → 'Andrew Pilaro'\n","  PERSON    1922: 1941  → 'W. Austin Lewis, IV'\n","  PERSON    2819: 2830  → 'David Ogden'\n","  PERSON    3657: 3671  → 'Laurie Bradley'\n","  PERSON    4673: 4684  → 'David Scott'\n","  PERSON    6112: 6125  → 'Andrew Pilaro'\n","  PERSON    7386: 7399  → 'Andrew Pilaro'\n","  PERSON     222:  237  → 'W. Austin Lewis'\n","  TITLE      242:  253  → 'Interim CEO'\n","  TITLE      255:  258  → 'CFO'\n","  TITLE      271:  274  → 'COO'\n","  TITLE        9:   17  → 'Director'\n","\n","SIDE-BY-SIDE EXAMPLES\n","------------------------------\n","\n","PRED TITLE 250:253\n","cers of PAID:\n","Name\n","Age\n","Position\n","W. Austin Lewis, IV\n","Interim [[CEO]], CFO\n","David Scott\n","COO\n","Andrew Pilaro\n","Director\n","Laurie Bradley\n","\n","\n","PRED TITLE 255:258\n","of PAID:\n","Name\n","Age\n","Position\n","W. Austin Lewis, IV\n","Interim CEO, [[CFO]]\n","David Scott\n","COO\n","Andrew Pilaro\n","Director\n","Laurie Bradley\n","Direc\n","\n","PRED PERSON 259:270\n","AID:\n","Name\n","Age\n","Position\n","W. Austin Lewis, IV\n","Interim CEO, CFO\n","[[David Scott]]\n","COO\n","Andrew Pilaro\n","Director\n","Laurie Bradley\n","Director\n","David Og\n","\n","PRED TITLE 271:274\n","e\n","Position\n","W. Austin Lewis, IV\n","Interim CEO, CFO\n","David Scott\n","[[COO]]\n","Andrew Pilaro\n","Director\n","Laurie Bradley\n","Director\n","David Ogden\n","\n","\n","PRED PERSON 275:288\n","sition\n","W. Austin Lewis, IV\n","Interim CEO, CFO\n","David Scott\n","COO\n","[[Andrew Pilaro]]\n","Director\n","Laurie Bradley\n","Director\n","David Ogden\n","Director\n","Andre\n","\n","GOLD PERSON 222:241\n","directors and executive officers of PAID:\n","Name\n","Age\n","Position\n","[[W. Austin Lewis, IV]]\n","Interim CEO, CFO\n","David Scott\n","COO\n","Andrew Pilaro\n","Director\n","Lau\n","\n","GOLD PERSON 259:270\n","AID:\n","Name\n","Age\n","Position\n","W. Austin Lewis, IV\n","Interim CEO, CFO\n","[[David Scott]]\n","COO\n","Andrew Pilaro\n","Director\n","Laurie Bradley\n","Director\n","David Og\n","\n","GOLD PERSON 275:288\n","sition\n","W. Austin Lewis, IV\n","Interim CEO, CFO\n","David Scott\n","COO\n","[[Andrew Pilaro]]\n","Director\n","Laurie Bradley\n","Director\n","David Ogden\n","Director\n","Andre\n","\n","GOLD PERSON 298:312\n"," IV\n","Interim CEO, CFO\n","David Scott\n","COO\n","Andrew Pilaro\n","Director\n","[[Laurie Bradley]]\n","Director\n","David Ogden\n","Director\n","Andrew Pilaro was elected as \n","\n","GOLD PERSON 322:333\n","id Scott\n","COO\n","Andrew Pilaro\n","Director\n","Laurie Bradley\n","Director\n","[[David Ogden]]\n","Director\n","Andrew Pilaro was elected as of September 19, 2000\n"]}]},{"cell_type":"code","source":["from pathlib import Path\n","\n","EXPORT_DIR = Path(PROJECT_ROOT) / \"exports\"\n","EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","scores_path = EXPORT_DIR / \"scores_per_doc.csv\"\n","micro_path  = EXPORT_DIR / \"scores_micro.csv\"\n","\n","scores_df.to_csv(scores_path, index=False)\n","micro_df.to_csv(micro_path, index=False)\n","\n","print(\"Wrote:\", scores_path)\n","print(\"Wrote:\", micro_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wx3U6S4XqnyA","executionInfo":{"status":"ok","timestamp":1767373466027,"user_tz":360,"elapsed":41,"user":{"displayName":"Ali Bridgers","userId":"01264324247454677030"}},"outputId":"6b451d27-52d9-4250-99cd-d9db73c98cee"},"id":"Wx3U6S4XqnyA","execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Wrote: /content/drive/MyDrive/Task 3/exports/scores_per_doc.csv\n","Wrote: /content/drive/MyDrive/Task 3/exports/scores_micro.csv\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}